{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TP4: Estimación de peso y dimensiones de los envíos de Mercado Libre\n",
    "\n",
    "# Materia: Aprendizaje supervisado\n",
    "\n",
    "## Análisis del dataset. Comunicación de resultados y conclusiones\n",
    "\n",
    "A partir de lo visto en la teoría de la materia y del cuarto laboratorio, diagramar una comunicación en formato textual o interactivo describiendo la solución de las actividades propuestas a continuación. Al final de las mismas se proveen actividades opcionales (no obligatorias) que pueden resultar de interés.\n",
    "\n",
    "### Actividades Propuestas:\n",
    "\n",
    "    1. Splitear el dataset en train/test (80-20). Recordar la utilidad train_test_split de scikit-learn y utilizar los parámetros `random_state` y `stratify` y explicar su función. El target en este práctico será múltiple: SHP_WEIGHT , SHP_LENGTH , SHP_HEIGHT y SHP_WIDTH . Esto significa que los modelos deberán predecir 4 valores en simultáneo en vez de 1.\n",
    "    \n",
    "    2. Entrenar y evaluar con al menos 3 nuevos modelos (Sugerencias: SVR , RandomForestRegressor, GradientBoostingRegressor, etc.) Obligatorio: Probar con una red neuronal. Puede ser de scikit-learn o de alguna otra librería que deseen como keras , pytorch , etc.). Junto con las métricas debe entregarse una breve descripción de cómo funciona cada modelo. Importante: Para evaluar, por ejemplo mean_absolute_error provee un parámetro multioutput que debería tomar el valor ` raw_values ` para reportar métricas para cada dimension de output por separado.\n",
    "    \n",
    "    3. Para estos nuevos modelos tunear hiper-parámetros. Para las evaluaciones utilizar la técnica de k-fold cross-validation (ver cross-validation ) y explicar los resultados.\n",
    "\n",
    "    4. Elegir el mejor modelo entrenado hasta el momento según f1-score. Comparar las métricas de este modelo vs. las métricas de evaluar 4 modelos por separado, un modelo para cada uno de los targets. Interpretar los resultados. \n",
    "    \n",
    "La comunicación debe estar apuntada a un público técnico pero sin conocimiento del tema particular, como por ejemplo, sus compañeros de clase o stakeholders del proyecto. Idealmente, además del documento se debería generar una presentación corta para stakeholders explicando el análisis realizado sobre los datos y las conclusiones obtenidas de tal análisis.\n",
    "    \n",
    "Se evaluarán los siguientes aspectos:\n",
    "\n",
    "    ● El informe debe contener un mensaje claro y presentado de forma concisa.\n",
    "    ● Los gráficos deben aplicar los conceptos de percepción visual vistos en clase.\n",
    "    ● Se debe describir o estimar la significancia estadística de su trabajo.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn\n",
    "import scipy as sc\n",
    "from math import sqrt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from ast import literal_eval\n",
    "from pandas.io.json import json_normalize\n",
    "from fancyimpute import KNN\n",
    "#extras para TP4\n",
    "from sklearn.metrics import mean_absolute_error, median_absolute_error, mean_squared_error, make_scorer\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.neural_network import MLPRegressor \n",
    "#import tensorflow as tf\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from visualization import plot_confusion_matrix, plot_learning_curve\n",
    "#import os\n",
    "#import sys\n",
    "#sys.path.append(os.getcwd())\n",
    "#from ml.visualization import plot_confusion_matrix, plot_learning_curve\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(0)\n",
    "DATASET = '../meli_dataset_20190426.csv'\n",
    "df_original = pd.read_csv(DATASET, low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= df_original\n",
    "df = df.head(10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocesamiento:  \n",
    "\n",
    "En base a lo desarrollado en el TP2 se eliminan los registros con `STATUS` 404 o con faltantes en la variables `SHP`, se agrupa por `ITEM_ID` y se reemplaza por la mediana. Además, se codifican algunas variables categóricas y se imputan valores a los faltantes de la variable `PRICE`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminación de registros con status 404\n",
    "df = df[df.STATUS != \"404\"]\n",
    "df = df.drop(columns=['STATUS'])\n",
    "df.sample(5)\n",
    "\n",
    "# Eliminación de registros con faltantes en las variables SHP \n",
    "df = df.dropna(subset=['SHP_WEIGHT', 'SHP_LENGTH', 'SHP_WIDTH', 'SHP_HEIGHT'])\n",
    "\n",
    "# Agrupación por item id y reemplazo por mediana\n",
    "# Agrupamos por item_id\n",
    "df_grouped = df.groupby(['ITEM_ID'], as_index=False).median()\n",
    "#Ordenamos el dataframe por item_id\n",
    "df.sort_values('ITEM_ID', inplace = True)\n",
    "# Eliminamos filas con item_id duplicados\n",
    "df.drop_duplicates(subset='ITEM_ID', keep=False, inplace=True)\n",
    "# Actualizamos dataframe original con la mediana de pesos y medidas\n",
    "df.set_index('ITEM_ID', inplace=True)\n",
    "df.update(df_grouped.set_index('ITEM_ID', inplace=True))\n",
    "df.reset_index()\n",
    "\n",
    "# Binarización de CATALOG_PRODUCT_ID, CONDITION y DOMAIN_ID\n",
    "\n",
    "column = 'CATALOG_PRODUCT_ID'\n",
    "lb = LabelBinarizer()\n",
    "lb_results = lb.fit_transform(df[column])\n",
    "#pd.DataFrame(lb_results, columns=(column + '_') + pd.Series(lb.classes_)).head(10)\n",
    "CATALOG_PRODUCT_ID_ENCODED = pd.DataFrame(lb_results, columns=(column + '_') + pd.Series(lb.classes_))\n",
    "\n",
    "column = \"CONDITION\"\n",
    "lb = LabelBinarizer()\n",
    "lb_results = lb.fit_transform(df[column].astype(str))\n",
    "pd.DataFrame(lb_results, columns=(column + '_') + pd.Series(lb.classes_)).head(10)\n",
    "CONDITION_ENCODED = pd.DataFrame(lb_results, columns=(column + '_') + pd.Series(lb.classes_))\n",
    "\n",
    "column = 'DOMAIN_ID'\n",
    "lb = LabelBinarizer()\n",
    "lb_results = lb.fit_transform(df[column].astype(str))\n",
    "#pd.DataFrame(lb_results, columns=(column + '_') + pd.Series(lb.classes_)).head(10)\n",
    "DOMAIN_ID_ENCODED = pd.DataFrame(lb_results, columns=(column + '_') + pd.Series(lb.classes_))\n",
    "# Pegado de las variables categoricas codificadas al dataset\n",
    "df[\"id\"]=CONDITION_ENCODED.index\n",
    "df=df.set_index(\"id\")\n",
    "df = pd.concat([df,CATALOG_PRODUCT_ID_ENCODED, CONDITION_ENCODED, DOMAIN_ID_ENCODED], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SHP_WEIGHT</th>\n",
       "      <th>SHP_LENGTH</th>\n",
       "      <th>SHP_WIDTH</th>\n",
       "      <th>SHP_HEIGHT</th>\n",
       "      <th>ATTRIBUTES</th>\n",
       "      <th>CATALOG_PRODUCT_ID</th>\n",
       "      <th>CONDITION</th>\n",
       "      <th>DOMAIN_ID</th>\n",
       "      <th>PRICE</th>\n",
       "      <th>SELLER_ID</th>\n",
       "      <th>...</th>\n",
       "      <th>DOMAIN_ID_MLB-WIRELESS_ANTENNAS</th>\n",
       "      <th>DOMAIN_ID_MLB-WIRELESS_CHARGERS</th>\n",
       "      <th>DOMAIN_ID_MLB-WIRELESS_FM_TRANSMITTERS</th>\n",
       "      <th>DOMAIN_ID_MLB-WIRE_STRIPPERS</th>\n",
       "      <th>DOMAIN_ID_MLB-WOMEN_SWIMWEAR</th>\n",
       "      <th>DOMAIN_ID_MLB-WRENCHES</th>\n",
       "      <th>DOMAIN_ID_MLB-WRENCH_SETS</th>\n",
       "      <th>DOMAIN_ID_MLB-WRISTWATCHES</th>\n",
       "      <th>DOMAIN_ID_MLB-XENON_KITS</th>\n",
       "      <th>DOMAIN_ID_nan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>775.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>[{'id': 'BRAND', 'name': 'Marca', 'value_id': ...</td>\n",
       "      <td>H53U1H7Q5G</td>\n",
       "      <td>new</td>\n",
       "      <td>MLB-ENGINE_GASKET_SETS</td>\n",
       "      <td>750.00</td>\n",
       "      <td>QD3YJ9751S</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>6100.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>[{'id': 'BEDDING_SET_SIZE', 'name': 'Tamanho',...</td>\n",
       "      <td>H53U1H7Q5G</td>\n",
       "      <td>new</td>\n",
       "      <td>MLB-BEDDING_SETS</td>\n",
       "      <td>119.90</td>\n",
       "      <td>J3EY3QAB29</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>464.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>[{'id': 'BRAND', 'name': 'Marca', 'value_id': ...</td>\n",
       "      <td>H53U1H7Q5G</td>\n",
       "      <td>new</td>\n",
       "      <td>MLB-AUTOMOBILE_FUEL_PUMPS</td>\n",
       "      <td>349.90</td>\n",
       "      <td>NO4W1R9S3D</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>150.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>[{'id': 'BRAND', 'name': 'Marca', 'value_id': ...</td>\n",
       "      <td>H53U1H7Q5G</td>\n",
       "      <td>new</td>\n",
       "      <td>MLB-PENDRIVES</td>\n",
       "      <td>21.99</td>\n",
       "      <td>KIQX6YQZI4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>3719.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>[{'id': 'BRAND', 'name': 'Marca', 'value_id': ...</td>\n",
       "      <td>GITRVCM7WO</td>\n",
       "      <td>used</td>\n",
       "      <td>MLB-GAME_CONSOLES</td>\n",
       "      <td>849.00</td>\n",
       "      <td>ZQIKYCCZ7E</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3987</td>\n",
       "      <td>431.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>[{'id': 'CLOSING', 'name': 'Fecho', 'value_id'...</td>\n",
       "      <td>H53U1H7Q5G</td>\n",
       "      <td>new</td>\n",
       "      <td>MLB-FANNY_PACKS</td>\n",
       "      <td>69.90</td>\n",
       "      <td>GPWP5IFQEN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3988</td>\n",
       "      <td>150.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>[{'id': 'ITEM_CONDITION', 'name': 'Condição do...</td>\n",
       "      <td>H53U1H7Q5G</td>\n",
       "      <td>new</td>\n",
       "      <td>MLB-PORTABLE_ELECTRIC_MASSAGERS</td>\n",
       "      <td>7.50</td>\n",
       "      <td>OFLRK20BUP</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3989</td>\n",
       "      <td>3880.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>[{'id': 'BRAND', 'name': 'Marca', 'value_id': ...</td>\n",
       "      <td>H53U1H7Q5G</td>\n",
       "      <td>new</td>\n",
       "      <td>MLB-ENGINE_OILS</td>\n",
       "      <td>145.90</td>\n",
       "      <td>MQICEHKRH5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3990</td>\n",
       "      <td>1040.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>[{'id': 'BRAND', 'name': 'Marca', 'value_id': ...</td>\n",
       "      <td>CCNZQYJ1G6</td>\n",
       "      <td>new</td>\n",
       "      <td>MLB-ROUTERS</td>\n",
       "      <td>329.49</td>\n",
       "      <td>ANYX5441IO</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3991</td>\n",
       "      <td>260.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>H53U1H7Q5G</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S4YVILX78R</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3992 rows × 1324 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      SHP_WEIGHT  SHP_LENGTH  SHP_WIDTH  SHP_HEIGHT  \\\n",
       "0          775.0        50.0       20.0        10.0   \n",
       "1         6100.0        70.0       25.0         5.0   \n",
       "2          464.0        20.0       11.0        10.0   \n",
       "3          150.0        25.0       25.0        11.0   \n",
       "4         3719.0        42.0       34.0        13.0   \n",
       "...          ...         ...        ...         ...   \n",
       "3987       431.0        25.0       25.0         5.0   \n",
       "3988       150.0        20.0       20.0        20.0   \n",
       "3989      3880.0        36.0       24.0        13.0   \n",
       "3990      1040.0        28.0       18.0         8.0   \n",
       "3991       260.0        16.0       11.0         2.0   \n",
       "\n",
       "                                             ATTRIBUTES CATALOG_PRODUCT_ID  \\\n",
       "0     [{'id': 'BRAND', 'name': 'Marca', 'value_id': ...         H53U1H7Q5G   \n",
       "1     [{'id': 'BEDDING_SET_SIZE', 'name': 'Tamanho',...         H53U1H7Q5G   \n",
       "2     [{'id': 'BRAND', 'name': 'Marca', 'value_id': ...         H53U1H7Q5G   \n",
       "3     [{'id': 'BRAND', 'name': 'Marca', 'value_id': ...         H53U1H7Q5G   \n",
       "4     [{'id': 'BRAND', 'name': 'Marca', 'value_id': ...         GITRVCM7WO   \n",
       "...                                                 ...                ...   \n",
       "3987  [{'id': 'CLOSING', 'name': 'Fecho', 'value_id'...         H53U1H7Q5G   \n",
       "3988  [{'id': 'ITEM_CONDITION', 'name': 'Condição do...         H53U1H7Q5G   \n",
       "3989  [{'id': 'BRAND', 'name': 'Marca', 'value_id': ...         H53U1H7Q5G   \n",
       "3990  [{'id': 'BRAND', 'name': 'Marca', 'value_id': ...         CCNZQYJ1G6   \n",
       "3991                                                NaN         H53U1H7Q5G   \n",
       "\n",
       "     CONDITION                        DOMAIN_ID   PRICE   SELLER_ID  ...  \\\n",
       "0          new           MLB-ENGINE_GASKET_SETS  750.00  QD3YJ9751S  ...   \n",
       "1          new                 MLB-BEDDING_SETS  119.90  J3EY3QAB29  ...   \n",
       "2          new        MLB-AUTOMOBILE_FUEL_PUMPS  349.90  NO4W1R9S3D  ...   \n",
       "3          new                    MLB-PENDRIVES   21.99  KIQX6YQZI4  ...   \n",
       "4         used                MLB-GAME_CONSOLES  849.00  ZQIKYCCZ7E  ...   \n",
       "...        ...                              ...     ...         ...  ...   \n",
       "3987       new                  MLB-FANNY_PACKS   69.90  GPWP5IFQEN  ...   \n",
       "3988       new  MLB-PORTABLE_ELECTRIC_MASSAGERS    7.50  OFLRK20BUP  ...   \n",
       "3989       new                  MLB-ENGINE_OILS  145.90  MQICEHKRH5  ...   \n",
       "3990       new                      MLB-ROUTERS  329.49  ANYX5441IO  ...   \n",
       "3991       NaN                              NaN     NaN  S4YVILX78R  ...   \n",
       "\n",
       "     DOMAIN_ID_MLB-WIRELESS_ANTENNAS  DOMAIN_ID_MLB-WIRELESS_CHARGERS  \\\n",
       "0                                  0                                0   \n",
       "1                                  0                                0   \n",
       "2                                  0                                0   \n",
       "3                                  0                                0   \n",
       "4                                  0                                0   \n",
       "...                              ...                              ...   \n",
       "3987                               0                                0   \n",
       "3988                               0                                0   \n",
       "3989                               0                                0   \n",
       "3990                               0                                0   \n",
       "3991                               0                                0   \n",
       "\n",
       "      DOMAIN_ID_MLB-WIRELESS_FM_TRANSMITTERS  DOMAIN_ID_MLB-WIRE_STRIPPERS  \\\n",
       "0                                          0                             0   \n",
       "1                                          0                             0   \n",
       "2                                          0                             0   \n",
       "3                                          0                             0   \n",
       "4                                          0                             0   \n",
       "...                                      ...                           ...   \n",
       "3987                                       0                             0   \n",
       "3988                                       0                             0   \n",
       "3989                                       0                             0   \n",
       "3990                                       0                             0   \n",
       "3991                                       0                             0   \n",
       "\n",
       "      DOMAIN_ID_MLB-WOMEN_SWIMWEAR  DOMAIN_ID_MLB-WRENCHES  \\\n",
       "0                                0                       0   \n",
       "1                                0                       0   \n",
       "2                                0                       0   \n",
       "3                                0                       0   \n",
       "4                                0                       0   \n",
       "...                            ...                     ...   \n",
       "3987                             0                       0   \n",
       "3988                             0                       0   \n",
       "3989                             0                       0   \n",
       "3990                             0                       0   \n",
       "3991                             0                       0   \n",
       "\n",
       "      DOMAIN_ID_MLB-WRENCH_SETS  DOMAIN_ID_MLB-WRISTWATCHES  \\\n",
       "0                             0                           0   \n",
       "1                             0                           0   \n",
       "2                             0                           0   \n",
       "3                             0                           0   \n",
       "4                             0                           0   \n",
       "...                         ...                         ...   \n",
       "3987                          0                           0   \n",
       "3988                          0                           0   \n",
       "3989                          0                           0   \n",
       "3990                          0                           0   \n",
       "3991                          0                           0   \n",
       "\n",
       "      DOMAIN_ID_MLB-XENON_KITS  DOMAIN_ID_nan  \n",
       "0                            0              0  \n",
       "1                            0              0  \n",
       "2                            0              0  \n",
       "3                            0              0  \n",
       "4                            0              0  \n",
       "...                        ...            ...  \n",
       "3987                         0              0  \n",
       "3988                         0              0  \n",
       "3989                         0              0  \n",
       "3990                         0              0  \n",
       "3991                         0              1  \n",
       "\n",
       "[3992 rows x 1324 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imputación de faltantes de PRICE por KNN\n",
    "df_numeric = df.select_dtypes([np.number])\n",
    "df_filled = pd.DataFrame(KNN(3).fit_transform(df_numeric))\n",
    "df_filled.columns=df_numeric.columns\n",
    "df=df_filled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df_filled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Probablemente no se relize la transformación logarítmica, por ahora se comenta esta perte del código\n",
    "#np.log(df[\"SHP_WEIGHT\"])\n",
    "#df[\"SHP_WEIGHT_LOG\"] = np.log(df[\"SHP_WEIGHT\"])\n",
    "#df= df.drop(columns=[\"SHP_WEIGHT\", \"SHP_LENGTH\", \"SHP_WIDTH\", \"SHP_HEIGHT\",  \"CATALOG_PRODUCT_ID_A0RY70BE19\", 'CONDITION_nan', \"DOMAIN_ID_nan\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Actividad 1:    \n",
    "\n",
    "Splitear el dataset en train/test (80-20). Recordar la utilidad train_test_split de scikit-learn y utilizar los parámetros `random_state` y `stratify` y explicar su función. El target en este práctico será múltiple: SHP_WEIGHT , SHP_LENGTH , SHP_HEIGHT y SHP_WIDTH . Esto significa que los modelos deberán predecir 4 valores en simultáneo en vez de 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# división entre instancias y etiquetas\n",
    "\n",
    "X, y = df.iloc[:, 4:], df[['SHP_WEIGHT', 'SHP_LENGTH', 'SHP_WIDTH', 'SHP_HEIGHT']]\n",
    "\n",
    "# división entre entrenamiento y evaluación\n",
    "#stratify=y no se emplea porque no es problema de clasificación\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El parámetro stratify permite realizar un muestreo estratificado por clases del dataset. De este modo se obtienen conjuntos de entrenamiento y de testing que tienen la misma proporción de cada clase de la etiqueta que el dataset original (si estratificamos de acuerdo a la la etiqueta y). Al tratarse de un problema de regresión entendemos que no tiene sentido emplear dicho parámetro.\n",
    "\n",
    "Por su parte, el parámetro ramdom_state permite obtener la misma partición cada vez que se ejecuta el script."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Actividad 2:    \n",
    "\n",
    "Entrenar y evaluar con al menos 3 nuevos modelos (Sugerencias: SVR , RandomForestRegressor, GradientBoostingRegressor, etc.) Obligatorio: Probar con una red neuronal. Puede ser de scikit-learn o de alguna otra librería que deseen como keras , pytorch , etc.). Junto con las métricas debe entregarse una breve descripción de cómo funciona cada modelo. Importante: Para evaluar, por ejemplo mean_absolute_error provee un parámetro multioutput que debería tomar el valor ` raw_values ` para reportar métricas para cada dimension de output por separado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAE = make_scorer(mean_absolute_error,greater_is_better=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfr = RandomForestRegressor(n_estimators=10, n_jobs=1, random_state=42, criterion='mae', max_depth=20, max_features =100)\n",
    "rfr.fit(X_train, y_train)    \n",
    "y_pred_rfr=rfr.predict(X_test) \n",
    "mean_absolute_error(y_test, y_pred_rfr, multioutput='raw_values') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fitRFR=rfr.fit(X_train, y_train)  \n",
    "#from pprint import pprint\n",
    "#pprint(vars(fitRFR))\n",
    "#dir(fitRFR)\n",
    "#getattr(fitRFR, 'feature_importances_')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbr = GradientBoostingRegressor(n_estimators=10, random_state=42, criterion='mae', max_features=100, loss='lad')\n",
    "gbr.fit(X_train, y_train.iloc[:,0])   \n",
    "y_pred_gbr=gbr.predict(X_test)\n",
    "print('MAE en entrenamiento')\n",
    "print(mean_absolute_error(y_train.iloc[:,0], y_train))\n",
    "print('MAE en test')\n",
    "print(mean_absolute_error(y_test.iloc[:,0], y_pred_gbr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gbr.fit(X_train, y_train.iloc[:,0])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_pred_gbr=gbr.predict(X_test) \n",
    "#mean_absolute_error(y_test.iloc[:,0], y_pred_gbr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cuando se intenta estimar las cuatro variables en forma simultánea se obtiene un mensaje de error, lo que indica que probablemente el método solo funciona con una etiqueta. Por eso, por el momento solo se estima una de las variables SHP."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Red neuronal (MLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MLPRegressor(hidden_layer_sizes=(5,), activation='relu',\n",
    "                                       solver='adam',\n",
    "                                       learning_rate='adaptive',\n",
    "                                       max_iter=1000,\n",
    "                                       learning_rate_init=0.01,\n",
    "                                       alpha=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = MLPRegressor(hidden_layer_sizes=(10,),  activation='relu', solver='adam',    alpha=0.001,batch_size='auto',\n",
    "               learning_rate='constant', learning_rate_init=0.01, power_t=0.5, max_iter=1000, shuffle=True,\n",
    "               random_state=None, tol=0.0001, verbose=False, warm_start=False, momentum=0.9,\n",
    "               nesterovs_momentum=True, early_stopping=False, validation_fraction=0.1, beta_1=0.9, beta_2=0.999,\n",
    "               epsilon=1e-08)\n",
    "\n",
    "reg = reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_mlp = reg.predict(X_test)\n",
    "mean_absolute_error(y_test, y_pred_mlp, multioutput='raw_values') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Actividad 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta actividad directamente se tunean los hiperparámetros y se comparan los modelos de acuerdo al MAE. \n",
    "No se realiza la actividad 4, porque el score F1 no aplica a problemas de regresión. Se suple eas actividad justamente por medio del uso del MAE en esta actividad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# definición de métrica para usar con GridSearchCV\n",
    "MAE = make_scorer(mean_absolute_error,greater_is_better=False)\n",
    "# no se puede usar el argumento multioutput con el setting \"raw_values\" porque se el scorer debe ser un único número"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_forest_forecast(X_train,X_test,y_train, y_test):\n",
    "    \n",
    "    rfr = RandomForestRegressor(n_jobs=1, random_state=0)\n",
    "    param_grid = {'n_estimators': [10,20, 50], 'max_depth':[10,20,50]}\n",
    "    # 'n_estimators': [1000], 'max_features': [10,15,20,25], 'max_depth':[20,20,25,25,]}\n",
    "    model = GridSearchCV(estimator=rfr, param_grid=param_grid, n_jobs=1, cv=10, scoring=MAE)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_train = model.predict(X_train)\n",
    "    \n",
    "    print('Random forest regression...')\n",
    "    print('Mejores Parámetros:')\n",
    "    print(model.best_params_)\n",
    "    print('Best CV Score:')\n",
    "    print(-model.best_score_)\n",
    "    print('MAE en entrenamiento:')\n",
    "    print(mean_absolute_error(y_train, y_pred_train, multioutput= 'raw_values'))\n",
    "    print('MAE en test:')\n",
    "    print(mean_absolute_error(y_test, y_pred, multioutput= 'raw_values'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest_forecast(X_train,X_test,y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_boosting_forecast(X_train,X_test,y_train, y_test):\n",
    "    \n",
    "    gbr = GradientBoostingRegressor(loss='lad', random_state=5,criterion='mae')\n",
    "    param_grid = {'n_estimators': [10], 'learning_rate':[0.01,0.1,1,10]}\n",
    "    # 'n_estimators': [10], 'max_features': [10,15,20,25], 'learning_rate':[0.01,0.1,1,10]}\n",
    "    model = GridSearchCV(estimator=gbr, param_grid=param_grid,  cv=10)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_train = model.predict(X_train)\n",
    "    \n",
    "    print('Gradient boosting regression...')\n",
    "    print('Mejores Parámetros:')\n",
    "    print(model.best_params_)\n",
    "    print('Best CV Score:')\n",
    "    print(-model.best_score_)\n",
    "    print('MAE en entrenamiento:')\n",
    "    print(mean_absolute_error(y_train, y_pred_train, multioutput= 'raw_values'))\n",
    "    print('MAE en test:')\n",
    "    print(mean_absolute_error(y_test, y_pred, multioutput= 'raw_values'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradient_boosting_forecast(X_train,X_test,y_train.iloc[:,0], y_test.iloc[:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Red neuronal (MLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_layer_perceptron_forecast(X_train,X_test,y_train, y_test):\n",
    "    \n",
    "    mlp = MLPRegressor()\n",
    "    param_grid = {'solver': ['lbfgs'], 'max_iter': [1000 ], 'alpha': 10.0 ** -np.arange(1, 2), \n",
    "                  'hidden_layer_sizes':10*np.arange(10, 15), 'random_state':[5]}\n",
    "    model = GridSearchCV(estimator=mlp, param_grid=param_grid,  cv=10)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_train = model.predict(X_train)\n",
    "    \n",
    "    print('Multi-layer perceptron regression...')\n",
    "    print('Mejores Parámetros:')\n",
    "    print(model.best_params_)\n",
    "    print('Best CV Score:')\n",
    "    print(-model.best_score_)\n",
    "    print('MAE en entrenamiento:')\n",
    "    print(mean_absolute_error(y_train, y_pred_train, multioutput= 'raw_values'))\n",
    "    print('MAE en test:')\n",
    "    print(mean_absolute_error(y_test, y_pred, multioutput= 'raw_values'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_layer_perceptron_forecast(X_train,X_test,y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parameters = {'solver': ['adam'], 'max_iter': [1000 ], 'alpha': 10.0 ** -np.arange(1, 2), 'hidden_layer_sizes':np.arange(10, 15), 'random_state':[5]}\n",
    "#reg = GridSearchCV(MLPRegressor(), parameters, n_jobs=-1, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reg.fit(X_train, y_train)\n",
    "#print(reg.score(X_train, y_train))\n",
    "#print(reg.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_pred_mlp=reg.predict(X_test)\n",
    "#mean_absolute_error(y_test, y_pred_mlp, multioutput= 'raw_values') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Actividad 4\n",
    "\n",
    "Elegir el mejor modelo entrenado hasta el momento según f1-score. Comparar las métricas de este modelo vs. las métricas de evaluar 4 modelos por separado, un modelo para cada uno de los targets. Interpretar los resultados. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No se emplea el f1-score porque no aplica a problemas de regresión. En la actividad 3 se computaron las métricas MAE, para cada uno de los modelos seleccionados, dando mejores resultados la regresión random forest. En esta actividad se agregan las métricas que se obtienen al estimar modelos para cada variable por separado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regresiones con un solo output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regresiones random forest con un output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def univariate_random_forest_forecast(X_train,X_test,y_train, y_test):\n",
    "    \n",
    "    rfr = RandomForestRegressor(n_jobs=1, random_state=0)\n",
    "    param_grid = {'n_estimators': [10,20, 50], 'max_depth':[10,20,50]}\n",
    "    # 'n_estimators': [1000], 'max_features': [10,15,20,25], 'max_depth':[20,20,25,25,]}\n",
    "    model = GridSearchCV(estimator=rfr, param_grid=param_grid, n_jobs=1, cv=10, scoring=MAE)\n",
    "    model.fit(X_train, y_train.iloc[:,0])\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_train = model.predict(X_train)\n",
    "    \n",
    "    print('Random forest regression para SHP_WEIGHT')\n",
    "    print('Mejores Parámetros:')\n",
    "    print(model.best_params_)\n",
    "    print('Best CV Score:')\n",
    "    print(-model.best_score_)\n",
    "    print('MAE en entrenamiento:')\n",
    "    print(mean_absolute_error(y_train.iloc[:,0], y_pred_train))\n",
    "    print('MAE en test:')\n",
    "    print(mean_absolute_error(y_test.iloc[:,0], y_pred))\n",
    "    \n",
    "    rfr = RandomForestRegressor(n_jobs=1, random_state=0)\n",
    "    param_grid = {'n_estimators': [10,20, 50], 'max_depth':[10,20,50]}\n",
    "    # 'n_estimators': [1000], 'max_features': [10,15,20,25], 'max_depth':[20,20,25,25,]}\n",
    "    model = GridSearchCV(estimator=rfr, param_grid=param_grid, n_jobs=1, cv=10, scoring=MAE)\n",
    "    model.fit(X_train, y_train.iloc[:,1])\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_train = model.predict(X_train)\n",
    "    \n",
    "    print('Random forest regression para SHP_LENGTH')\n",
    "    print('Mejores Parámetros:')\n",
    "    print(model.best_params_)\n",
    "    print('Best CV Score:')\n",
    "    print(-model.best_score_)\n",
    "    print('MAE en entrenamiento:')\n",
    "    print(mean_absolute_error(y_train.iloc[:,1], y_pred_train))\n",
    "    print('MAE en test:')\n",
    "    print(mean_absolute_error(y_test.iloc[:,1], y_pred))\n",
    "    \n",
    "    rfr = RandomForestRegressor(n_jobs=1, random_state=0)\n",
    "    param_grid = {'n_estimators': [10,20, 50], 'max_depth':[10,20,50]}\n",
    "    # 'n_estimators': [1000], 'max_features': [10,15,20,25], 'max_depth':[20,20,25,25,]}\n",
    "    model = GridSearchCV(estimator=rfr, param_grid=param_grid, n_jobs=1, cv=10, scoring=MAE)\n",
    "    model.fit(X_train, y_train.iloc[:,2])\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_train = model.predict(X_train)\n",
    "    \n",
    "    print('Random forest regression para SHP_WIDTH')\n",
    "    print('Mejores Parámetros:')\n",
    "    print(model.best_params_)\n",
    "    print('Best CV Score:')\n",
    "    print(-model.best_score_)\n",
    "    print('MAE en entrenamiento:')\n",
    "    print(mean_absolute_error(y_train.iloc[:,2], y_pred_train))\n",
    "    print('MAE en test:')\n",
    "    print(mean_absolute_error(y_test.iloc[:,2], y_pred))\n",
    "    \n",
    "    rfr = RandomForestRegressor(n_jobs=1, random_state=0)\n",
    "    param_grid = {'n_estimators': [10,20, 50], 'max_depth':[10,20,50]}\n",
    "    # 'n_estimators': [1000], 'max_features': [10,15,20,25], 'max_depth':[20,20,25,25,]}\n",
    "    model = GridSearchCV(estimator=rfr, param_grid=param_grid, n_jobs=1, cv=10, scoring=MAE)\n",
    "    model.fit(X_train, y_train.iloc[:,3])\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_train = model.predict(X_train)\n",
    "    \n",
    "    print('Random forest regression para SHP_HEIGHT')\n",
    "    print('Mejores Parámetros:')\n",
    "    print(model.best_params_)\n",
    "    print('Best CV Score:')\n",
    "    print(-model.best_score_)\n",
    "    print('MAE en entrenamiento:')\n",
    "    print(mean_absolute_error(y_train.iloc[:,3], y_pred_train))\n",
    "    print('MAE en test:')\n",
    "    print(mean_absolute_error(y_test.iloc[:,3], y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "univariate_random_forest_forecast(X_train,X_test,y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regresiones MLP con un output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def univariate_multi_layer_perceptron_forecast(X_train,X_test,y_train, y_test):\n",
    "    \n",
    "    mlp = MLPRegressor()\n",
    "    param_grid = {'solver': ['lbfgs'], 'max_iter': [1000 ], 'alpha': 10.0 ** -np.arange(1, 2), \n",
    "                  'hidden_layer_sizes':10*np.arange(10, 15), 'random_state':[5]}\n",
    "    model = GridSearchCV(estimator=mlp, param_grid=param_grid,  cv=10)\n",
    "    model.fit(X_train, y_train.iloc[:0])\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_train = model.predict(X_train)\n",
    "    print('Multi-layer perceptron regression para SHP_WEIGHT')\n",
    "    print('Mejores Parámetros:')\n",
    "    print(model.best_params_)\n",
    "    print('Best CV Score:')\n",
    "    print(-model.best_score_)\n",
    "    print('MAE en entrenamiento:')\n",
    "    print(mean_absolute_error(y_train.iloc[:0], y_pred_train))\n",
    "    print('MAE en test:')\n",
    "    print(mean_absolute_error(y_test.iloc[:0], y_pred))\n",
    "    \n",
    "    mlp = MLPRegressor()\n",
    "    param_grid = {'solver': ['lbfgs'], 'max_iter': [1000 ], 'alpha': 10.0 ** -np.arange(1, 2), \n",
    "                  'hidden_layer_sizes':10*np.arange(10, 15), 'random_state':[5]}\n",
    "    model = GridSearchCV(estimator=mlp, param_grid=param_grid,  cv=10)\n",
    "    model.fit(X_train, y_train.iloc[:1])\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_train = model.predict(X_train)\n",
    "    print('Multi-layer perceptron regression para SHP_LENGTH')\n",
    "    print('Mejores Parámetros:')\n",
    "    print(model.best_params_)\n",
    "    print('Best CV Score:')\n",
    "    print(-model.best_score_)\n",
    "    print('MAE en entrenamiento:')\n",
    "    print(mean_absolute_error(y_train.iloc[:1], y_pred_train))\n",
    "    print('MAE en test:')\n",
    "    print(mean_absolute_error(y_test.iloc[:1], y_pred))\n",
    "    \n",
    "    mlp = MLPRegressor()\n",
    "    param_grid = {'solver': ['lbfgs'], 'max_iter': [1000 ], 'alpha': 10.0 ** -np.arange(1, 2), \n",
    "                  'hidden_layer_sizes':10*np.arange(10, 15), 'random_state':[5]}\n",
    "    model = GridSearchCV(estimator=mlp, param_grid=param_grid,  cv=10)\n",
    "    model.fit(X_train, y_train.iloc[:2])\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_train = model.predict(X_train)\n",
    "    print('Multi-layer perceptron regression para SHP_WIDTH')\n",
    "    print('Mejores Parámetros:')\n",
    "    print(model.best_params_)\n",
    "    print('Best CV Score:')\n",
    "    print(-model.best_score_)\n",
    "    print('MAE en entrenamiento:')\n",
    "    print(mean_absolute_error(y_train.iloc[:2], y_pred_train))\n",
    "    print('MAE en test:')\n",
    "    print(mean_absolute_error(y_test.iloc[:2], y_pred))\n",
    "    \n",
    "    mlp = MLPRegressor()\n",
    "    param_grid = {'solver': ['lbfgs'], 'max_iter': [1000 ], 'alpha': 10.0 ** -np.arange(1, 2), \n",
    "                  'hidden_layer_sizes':10*np.arange(10, 15), 'random_state':[5]}\n",
    "    model = GridSearchCV(estimator=mlp, param_grid=param_grid,  cv=10)\n",
    "    model.fit(X_train, y_train.iloc[:3])\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_train = model.predict(X_train)\n",
    "    print('Multi-layer perceptron regression para SHP_HEIGHT')\n",
    "    print('Mejores Parámetros:')\n",
    "    print(model.best_params_)\n",
    "    print('Best CV Score:')\n",
    "    print(-model.best_score_)\n",
    "    print('MAE en entrenamiento:')\n",
    "    print(mean_absolute_error(y_train.iloc[:3], y_pred_train))\n",
    "    print('MAE en test:')\n",
    "    print(mean_absolute_error(y_test.iloc[:3], y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "univariate_multi_layer_perceptron_forecast(X_train,X_test,y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
