{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TP4: Estimación de peso y dimensiones de los envíos de Mercado Libre\n",
    "\n",
    "# Materia: Aprendizaje supervisado\n",
    "\n",
    "## Análisis del dataset. Comunicación de resultados y conclusiones\n",
    "\n",
    "A partir de lo visto en la teoría de la materia y del cuarto laboratorio, diagramar una comunicación en formato textual o interactivo describiendo la solución de las actividades propuestas a continuación. Al final de las mismas se proveen actividades opcionales (no obligatorias) que pueden resultar de interés.\n",
    "\n",
    "### Actividades Propuestas:\n",
    "\n",
    "    1. Splitear el dataset en train/test (80-20). Recordar la utilidad train_test_split de scikit-learn y utilizar los parámetros `random_state` y `stratify` y explicar su función. El target en este práctico será múltiple: SHP_WEIGHT , SHP_LENGTH , SHP_HEIGHT y SHP_WIDTH . Esto significa que los modelos deberán predecir 4 valores en simultáneo en vez de 1.\n",
    "    \n",
    "    2. Entrenar y evaluar con al menos 3 nuevos modelos (Sugerencias: SVR , RandomForestRegressor, GradientBoostingRegressor, etc.) Obligatorio: Probar con una red neuronal. Puede ser de scikit-learn o de alguna otra librería que deseen como keras , pytorch , etc.). Junto con las métricas debe entregarse una breve descripción de cómo funciona cada modelo. Importante: Para evaluar, por ejemplo mean_absolute_error provee un parámetro multioutput que debería tomar el valor ` raw_values ` para reportar métricas para cada dimension de output por separado.\n",
    "    \n",
    "    3. Para estos nuevos modelos tunear hiper-parámetros. Para las evaluaciones utilizar la técnica de k-fold cross-validation (ver cross-validation ) y explicar los resultados.\n",
    "\n",
    "    4. Elegir el mejor modelo entrenado hasta el momento según f1-score. Comparar las métricas de este modelo vs. las métricas de evaluar 4 modelos por separado, un modelo para cada uno de los targets. Interpretar los resultados. \n",
    "    \n",
    "La comunicación debe estar apuntada a un público técnico pero sin conocimiento del tema particular, como por ejemplo, sus compañeros de clase o stakeholders del proyecto. Idealmente, además del documento se debería generar una presentación corta para stakeholders explicando el análisis realizado sobre los datos y las conclusiones obtenidas de tal análisis.\n",
    "    \n",
    "Se evaluarán los siguientes aspectos:\n",
    "\n",
    "    ● El informe debe contener un mensaje claro y presentado de forma concisa.\n",
    "    ● Los gráficos deben aplicar los conceptos de percepción visual vistos en clase.\n",
    "    ● Se debe describir o estimar la significancia estadística de su trabajo.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn\n",
    "import scipy as sc\n",
    "from math import sqrt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from ast import literal_eval\n",
    "from pandas.io.json import json_normalize\n",
    "from fancyimpute import KNN\n",
    "#extras para TP4\n",
    "from sklearn.metrics import mean_absolute_error, median_absolute_error, mean_squared_error, make_scorer\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.neural_network import MLPRegressor \n",
    "#import tensorflow as tf\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from visualization import plot_confusion_matrix, plot_learning_curve\n",
    "#import os\n",
    "#import sys\n",
    "#sys.path.append(os.getcwd())\n",
    "#from ml.visualization import plot_confusion_matrix, plot_learning_curve\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(0)\n",
    "DATASET = '../meli_dataset_20190426.csv'\n",
    "df_original = pd.read_csv(DATASET, low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= df_original\n",
    "df = df.head(10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocesamiento:  \n",
    "\n",
    "En base a lo desarrollado en el TP2 se eliminan los registros con `STATUS` 404 o con faltantes en la variables `SHP`, se agrupa por `ITEM_ID` y se reemplaza por la mediana. Además, se codifican algunas variables categóricas y se imputan valores a los faltantes de la variable `PRICE`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminación de registros con status 404\n",
    "df = df[df.STATUS != \"404\"]\n",
    "df = df.drop(columns=['STATUS'])\n",
    "df.sample(5)\n",
    "\n",
    "# Eliminación de registros con faltantes en las variables SHP \n",
    "df = df.dropna(subset=['SHP_WEIGHT', 'SHP_LENGTH', 'SHP_WIDTH', 'SHP_HEIGHT'])\n",
    "\n",
    "# Agrupación por item id y reemplazo por mediana\n",
    "# Agrupamos por item_id\n",
    "df_grouped = df.groupby(['ITEM_ID'], as_index=False).median()\n",
    "#Ordenamos el dataframe por item_id\n",
    "df.sort_values('ITEM_ID', inplace = True)\n",
    "# Eliminamos filas con item_id duplicados\n",
    "df.drop_duplicates(subset='ITEM_ID', keep=False, inplace=True)\n",
    "# Actualizamos dataframe original con la mediana de pesos y medidas\n",
    "df.set_index('ITEM_ID', inplace=True)\n",
    "df.update(df_grouped.set_index('ITEM_ID', inplace=True))\n",
    "df.reset_index()\n",
    "\n",
    "# Binarización de CATALOG_PRODUCT_ID, CONDITION y DOMAIN_ID\n",
    "\n",
    "column = 'CATALOG_PRODUCT_ID'\n",
    "lb = LabelBinarizer()\n",
    "lb_results = lb.fit_transform(df[column])\n",
    "#pd.DataFrame(lb_results, columns=(column + '_') + pd.Series(lb.classes_)).head(10)\n",
    "CATALOG_PRODUCT_ID_ENCODED = pd.DataFrame(lb_results, columns=(column + '_') + pd.Series(lb.classes_))\n",
    "\n",
    "column = \"CONDITION\"\n",
    "lb = LabelBinarizer()\n",
    "lb_results = lb.fit_transform(df[column].astype(str))\n",
    "pd.DataFrame(lb_results, columns=(column + '_') + pd.Series(lb.classes_)).head(10)\n",
    "CONDITION_ENCODED = pd.DataFrame(lb_results, columns=(column + '_') + pd.Series(lb.classes_))\n",
    "\n",
    "column = 'DOMAIN_ID'\n",
    "lb = LabelBinarizer()\n",
    "lb_results = lb.fit_transform(df[column].astype(str))\n",
    "#pd.DataFrame(lb_results, columns=(column + '_') + pd.Series(lb.classes_)).head(10)\n",
    "DOMAIN_ID_ENCODED = pd.DataFrame(lb_results, columns=(column + '_') + pd.Series(lb.classes_))\n",
    "# Pegado de las variables categoricas codificadas al dataset\n",
    "df[\"id\"]=CONDITION_ENCODED.index\n",
    "df=df.set_index(\"id\")\n",
    "df = pd.concat([df,CATALOG_PRODUCT_ID_ENCODED, CONDITION_ENCODED, DOMAIN_ID_ENCODED], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SHP_WEIGHT</th>\n",
       "      <th>SHP_LENGTH</th>\n",
       "      <th>SHP_WIDTH</th>\n",
       "      <th>SHP_HEIGHT</th>\n",
       "      <th>ATTRIBUTES</th>\n",
       "      <th>CATALOG_PRODUCT_ID</th>\n",
       "      <th>CONDITION</th>\n",
       "      <th>DOMAIN_ID</th>\n",
       "      <th>PRICE</th>\n",
       "      <th>SELLER_ID</th>\n",
       "      <th>...</th>\n",
       "      <th>DOMAIN_ID_MLB-WIRELESS_ANTENNAS</th>\n",
       "      <th>DOMAIN_ID_MLB-WIRELESS_CHARGERS</th>\n",
       "      <th>DOMAIN_ID_MLB-WIRELESS_FM_TRANSMITTERS</th>\n",
       "      <th>DOMAIN_ID_MLB-WIRE_STRIPPERS</th>\n",
       "      <th>DOMAIN_ID_MLB-WOMEN_SWIMWEAR</th>\n",
       "      <th>DOMAIN_ID_MLB-WRENCHES</th>\n",
       "      <th>DOMAIN_ID_MLB-WRENCH_SETS</th>\n",
       "      <th>DOMAIN_ID_MLB-WRISTWATCHES</th>\n",
       "      <th>DOMAIN_ID_MLB-XENON_KITS</th>\n",
       "      <th>DOMAIN_ID_nan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>775.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>[{'id': 'BRAND', 'name': 'Marca', 'value_id': ...</td>\n",
       "      <td>H53U1H7Q5G</td>\n",
       "      <td>new</td>\n",
       "      <td>MLB-ENGINE_GASKET_SETS</td>\n",
       "      <td>750.00</td>\n",
       "      <td>QD3YJ9751S</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>6100.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>[{'id': 'BEDDING_SET_SIZE', 'name': 'Tamanho',...</td>\n",
       "      <td>H53U1H7Q5G</td>\n",
       "      <td>new</td>\n",
       "      <td>MLB-BEDDING_SETS</td>\n",
       "      <td>119.90</td>\n",
       "      <td>J3EY3QAB29</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>464.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>[{'id': 'BRAND', 'name': 'Marca', 'value_id': ...</td>\n",
       "      <td>H53U1H7Q5G</td>\n",
       "      <td>new</td>\n",
       "      <td>MLB-AUTOMOBILE_FUEL_PUMPS</td>\n",
       "      <td>349.90</td>\n",
       "      <td>NO4W1R9S3D</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>150.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>[{'id': 'BRAND', 'name': 'Marca', 'value_id': ...</td>\n",
       "      <td>H53U1H7Q5G</td>\n",
       "      <td>new</td>\n",
       "      <td>MLB-PENDRIVES</td>\n",
       "      <td>21.99</td>\n",
       "      <td>KIQX6YQZI4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>3719.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>[{'id': 'BRAND', 'name': 'Marca', 'value_id': ...</td>\n",
       "      <td>GITRVCM7WO</td>\n",
       "      <td>used</td>\n",
       "      <td>MLB-GAME_CONSOLES</td>\n",
       "      <td>849.00</td>\n",
       "      <td>ZQIKYCCZ7E</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3987</td>\n",
       "      <td>431.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>[{'id': 'CLOSING', 'name': 'Fecho', 'value_id'...</td>\n",
       "      <td>H53U1H7Q5G</td>\n",
       "      <td>new</td>\n",
       "      <td>MLB-FANNY_PACKS</td>\n",
       "      <td>69.90</td>\n",
       "      <td>GPWP5IFQEN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3988</td>\n",
       "      <td>150.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>[{'id': 'ITEM_CONDITION', 'name': 'Condição do...</td>\n",
       "      <td>H53U1H7Q5G</td>\n",
       "      <td>new</td>\n",
       "      <td>MLB-PORTABLE_ELECTRIC_MASSAGERS</td>\n",
       "      <td>7.50</td>\n",
       "      <td>OFLRK20BUP</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3989</td>\n",
       "      <td>3880.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>[{'id': 'BRAND', 'name': 'Marca', 'value_id': ...</td>\n",
       "      <td>H53U1H7Q5G</td>\n",
       "      <td>new</td>\n",
       "      <td>MLB-ENGINE_OILS</td>\n",
       "      <td>145.90</td>\n",
       "      <td>MQICEHKRH5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3990</td>\n",
       "      <td>1040.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>[{'id': 'BRAND', 'name': 'Marca', 'value_id': ...</td>\n",
       "      <td>CCNZQYJ1G6</td>\n",
       "      <td>new</td>\n",
       "      <td>MLB-ROUTERS</td>\n",
       "      <td>329.49</td>\n",
       "      <td>ANYX5441IO</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3991</td>\n",
       "      <td>260.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>H53U1H7Q5G</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S4YVILX78R</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3992 rows × 1324 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      SHP_WEIGHT  SHP_LENGTH  SHP_WIDTH  SHP_HEIGHT  \\\n",
       "0          775.0        50.0       20.0        10.0   \n",
       "1         6100.0        70.0       25.0         5.0   \n",
       "2          464.0        20.0       11.0        10.0   \n",
       "3          150.0        25.0       25.0        11.0   \n",
       "4         3719.0        42.0       34.0        13.0   \n",
       "...          ...         ...        ...         ...   \n",
       "3987       431.0        25.0       25.0         5.0   \n",
       "3988       150.0        20.0       20.0        20.0   \n",
       "3989      3880.0        36.0       24.0        13.0   \n",
       "3990      1040.0        28.0       18.0         8.0   \n",
       "3991       260.0        16.0       11.0         2.0   \n",
       "\n",
       "                                             ATTRIBUTES CATALOG_PRODUCT_ID  \\\n",
       "0     [{'id': 'BRAND', 'name': 'Marca', 'value_id': ...         H53U1H7Q5G   \n",
       "1     [{'id': 'BEDDING_SET_SIZE', 'name': 'Tamanho',...         H53U1H7Q5G   \n",
       "2     [{'id': 'BRAND', 'name': 'Marca', 'value_id': ...         H53U1H7Q5G   \n",
       "3     [{'id': 'BRAND', 'name': 'Marca', 'value_id': ...         H53U1H7Q5G   \n",
       "4     [{'id': 'BRAND', 'name': 'Marca', 'value_id': ...         GITRVCM7WO   \n",
       "...                                                 ...                ...   \n",
       "3987  [{'id': 'CLOSING', 'name': 'Fecho', 'value_id'...         H53U1H7Q5G   \n",
       "3988  [{'id': 'ITEM_CONDITION', 'name': 'Condição do...         H53U1H7Q5G   \n",
       "3989  [{'id': 'BRAND', 'name': 'Marca', 'value_id': ...         H53U1H7Q5G   \n",
       "3990  [{'id': 'BRAND', 'name': 'Marca', 'value_id': ...         CCNZQYJ1G6   \n",
       "3991                                                NaN         H53U1H7Q5G   \n",
       "\n",
       "     CONDITION                        DOMAIN_ID   PRICE   SELLER_ID  ...  \\\n",
       "0          new           MLB-ENGINE_GASKET_SETS  750.00  QD3YJ9751S  ...   \n",
       "1          new                 MLB-BEDDING_SETS  119.90  J3EY3QAB29  ...   \n",
       "2          new        MLB-AUTOMOBILE_FUEL_PUMPS  349.90  NO4W1R9S3D  ...   \n",
       "3          new                    MLB-PENDRIVES   21.99  KIQX6YQZI4  ...   \n",
       "4         used                MLB-GAME_CONSOLES  849.00  ZQIKYCCZ7E  ...   \n",
       "...        ...                              ...     ...         ...  ...   \n",
       "3987       new                  MLB-FANNY_PACKS   69.90  GPWP5IFQEN  ...   \n",
       "3988       new  MLB-PORTABLE_ELECTRIC_MASSAGERS    7.50  OFLRK20BUP  ...   \n",
       "3989       new                  MLB-ENGINE_OILS  145.90  MQICEHKRH5  ...   \n",
       "3990       new                      MLB-ROUTERS  329.49  ANYX5441IO  ...   \n",
       "3991       NaN                              NaN     NaN  S4YVILX78R  ...   \n",
       "\n",
       "     DOMAIN_ID_MLB-WIRELESS_ANTENNAS  DOMAIN_ID_MLB-WIRELESS_CHARGERS  \\\n",
       "0                                  0                                0   \n",
       "1                                  0                                0   \n",
       "2                                  0                                0   \n",
       "3                                  0                                0   \n",
       "4                                  0                                0   \n",
       "...                              ...                              ...   \n",
       "3987                               0                                0   \n",
       "3988                               0                                0   \n",
       "3989                               0                                0   \n",
       "3990                               0                                0   \n",
       "3991                               0                                0   \n",
       "\n",
       "      DOMAIN_ID_MLB-WIRELESS_FM_TRANSMITTERS  DOMAIN_ID_MLB-WIRE_STRIPPERS  \\\n",
       "0                                          0                             0   \n",
       "1                                          0                             0   \n",
       "2                                          0                             0   \n",
       "3                                          0                             0   \n",
       "4                                          0                             0   \n",
       "...                                      ...                           ...   \n",
       "3987                                       0                             0   \n",
       "3988                                       0                             0   \n",
       "3989                                       0                             0   \n",
       "3990                                       0                             0   \n",
       "3991                                       0                             0   \n",
       "\n",
       "      DOMAIN_ID_MLB-WOMEN_SWIMWEAR  DOMAIN_ID_MLB-WRENCHES  \\\n",
       "0                                0                       0   \n",
       "1                                0                       0   \n",
       "2                                0                       0   \n",
       "3                                0                       0   \n",
       "4                                0                       0   \n",
       "...                            ...                     ...   \n",
       "3987                             0                       0   \n",
       "3988                             0                       0   \n",
       "3989                             0                       0   \n",
       "3990                             0                       0   \n",
       "3991                             0                       0   \n",
       "\n",
       "      DOMAIN_ID_MLB-WRENCH_SETS  DOMAIN_ID_MLB-WRISTWATCHES  \\\n",
       "0                             0                           0   \n",
       "1                             0                           0   \n",
       "2                             0                           0   \n",
       "3                             0                           0   \n",
       "4                             0                           0   \n",
       "...                         ...                         ...   \n",
       "3987                          0                           0   \n",
       "3988                          0                           0   \n",
       "3989                          0                           0   \n",
       "3990                          0                           0   \n",
       "3991                          0                           0   \n",
       "\n",
       "      DOMAIN_ID_MLB-XENON_KITS  DOMAIN_ID_nan  \n",
       "0                            0              0  \n",
       "1                            0              0  \n",
       "2                            0              0  \n",
       "3                            0              0  \n",
       "4                            0              0  \n",
       "...                        ...            ...  \n",
       "3987                         0              0  \n",
       "3988                         0              0  \n",
       "3989                         0              0  \n",
       "3990                         0              0  \n",
       "3991                         0              1  \n",
       "\n",
       "[3992 rows x 1324 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputing row 1/3992 with 0 missing, elapsed time: 209.165\n",
      "Imputing row 101/3992 with 0 missing, elapsed time: 209.175\n",
      "Imputing row 201/3992 with 0 missing, elapsed time: 209.182\n",
      "Imputing row 301/3992 with 0 missing, elapsed time: 209.189\n",
      "Imputing row 401/3992 with 0 missing, elapsed time: 209.196\n",
      "Imputing row 501/3992 with 0 missing, elapsed time: 209.202\n",
      "Imputing row 601/3992 with 0 missing, elapsed time: 209.209\n",
      "Imputing row 701/3992 with 0 missing, elapsed time: 209.217\n",
      "Imputing row 801/3992 with 0 missing, elapsed time: 209.227\n",
      "Imputing row 901/3992 with 0 missing, elapsed time: 209.235\n",
      "Imputing row 1001/3992 with 0 missing, elapsed time: 209.242\n",
      "Imputing row 1101/3992 with 0 missing, elapsed time: 209.250\n",
      "Imputing row 1201/3992 with 0 missing, elapsed time: 209.257\n",
      "Imputing row 1301/3992 with 0 missing, elapsed time: 209.265\n",
      "Imputing row 1401/3992 with 1 missing, elapsed time: 209.273\n",
      "Imputing row 1501/3992 with 0 missing, elapsed time: 209.280\n",
      "Imputing row 1601/3992 with 0 missing, elapsed time: 209.288\n",
      "Imputing row 1701/3992 with 1 missing, elapsed time: 209.295\n",
      "Imputing row 1801/3992 with 0 missing, elapsed time: 209.303\n",
      "Imputing row 1901/3992 with 0 missing, elapsed time: 209.310\n",
      "Imputing row 2001/3992 with 0 missing, elapsed time: 209.316\n",
      "Imputing row 2101/3992 with 0 missing, elapsed time: 209.324\n",
      "Imputing row 2201/3992 with 0 missing, elapsed time: 209.332\n",
      "Imputing row 2301/3992 with 0 missing, elapsed time: 209.339\n",
      "Imputing row 2401/3992 with 0 missing, elapsed time: 209.346\n",
      "Imputing row 2501/3992 with 0 missing, elapsed time: 209.356\n",
      "Imputing row 2601/3992 with 0 missing, elapsed time: 209.370\n",
      "Imputing row 2701/3992 with 0 missing, elapsed time: 209.378\n",
      "Imputing row 2801/3992 with 0 missing, elapsed time: 209.388\n",
      "Imputing row 2901/3992 with 0 missing, elapsed time: 209.396\n",
      "Imputing row 3001/3992 with 0 missing, elapsed time: 209.404\n",
      "Imputing row 3101/3992 with 0 missing, elapsed time: 209.412\n",
      "Imputing row 3201/3992 with 1 missing, elapsed time: 209.421\n",
      "Imputing row 3301/3992 with 1 missing, elapsed time: 209.431\n",
      "Imputing row 3401/3992 with 0 missing, elapsed time: 209.439\n",
      "Imputing row 3501/3992 with 0 missing, elapsed time: 209.447\n",
      "Imputing row 3601/3992 with 0 missing, elapsed time: 209.457\n",
      "Imputing row 3701/3992 with 0 missing, elapsed time: 209.468\n",
      "Imputing row 3801/3992 with 0 missing, elapsed time: 209.476\n",
      "Imputing row 3901/3992 with 0 missing, elapsed time: 209.483\n"
     ]
    }
   ],
   "source": [
    "# Imputación de faltantes de PRICE por KNN\n",
    "df_numeric = df.select_dtypes([np.number])\n",
    "df_filled = pd.DataFrame(KNN(3).fit_transform(df_numeric))\n",
    "df_filled.columns=df_numeric.columns\n",
    "df=df_filled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df_filled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Probablemente no se relize la transformación logarítmica, por ahora se comenta esta perte del código\n",
    "#np.log(df[\"SHP_WEIGHT\"])\n",
    "#df[\"SHP_WEIGHT_LOG\"] = np.log(df[\"SHP_WEIGHT\"])\n",
    "#df= df.drop(columns=[\"SHP_WEIGHT\", \"SHP_LENGTH\", \"SHP_WIDTH\", \"SHP_HEIGHT\",  \"CATALOG_PRODUCT_ID_A0RY70BE19\", 'CONDITION_nan', \"DOMAIN_ID_nan\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Actividad 1:    \n",
    "\n",
    "Splitear el dataset en train/test (80-20). Recordar la utilidad train_test_split de scikit-learn y utilizar los parámetros `random_state` y `stratify` y explicar su función. El target en este práctico será múltiple: SHP_WEIGHT , SHP_LENGTH , SHP_HEIGHT y SHP_WIDTH . Esto significa que los modelos deberán predecir 4 valores en simultáneo en vez de 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# división entre instancias y etiquetas\n",
    "\n",
    "X, y = df.iloc[:, 4:], df[['SHP_WEIGHT', 'SHP_LENGTH', 'SHP_WIDTH', 'SHP_HEIGHT']]\n",
    "\n",
    "# división entre entrenamiento y evaluación\n",
    "#stratify=y no se emplea porque no es problema de clasificación\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El parámetro stratify permite realizar un muestreo estratificado por clases del dataset. De este modo se obtienen conjuntos de entrenamiento y de testing que tienen la misma proporción de cada clase de la etiqueta que el dataset original (si estratificamos de acuerdo a la la etiqueta y). Al tratarse de un problema de regresión entendemos que no tiene sentido emplear dicho parámetro.\n",
    "\n",
    "Por su parte, el parámetro ramdom_state permite obtener la misma partición cada vez que se ejecuta el script."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Actividad 2:    \n",
    "\n",
    "Entrenar y evaluar con al menos 3 nuevos modelos (Sugerencias: SVR , RandomForestRegressor, GradientBoostingRegressor, etc.) Obligatorio: Probar con una red neuronal. Puede ser de scikit-learn o de alguna otra librería que deseen como keras , pytorch , etc.). Junto con las métricas debe entregarse una breve descripción de cómo funciona cada modelo. Importante: Para evaluar, por ejemplo mean_absolute_error provee un parámetro multioutput que debería tomar el valor ` raw_values ` para reportar métricas para cada dimension de output por separado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAE = make_scorer(mean_absolute_error,greater_is_better=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1444.73372966,   10.7539174 ,    7.92150188,    6.35844806])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfr = RandomForestRegressor(n_estimators=10, n_jobs=1, random_state=42, criterion='mae', max_depth=20, max_features =100)\n",
    "rfr.fit(X_train, y_train)    \n",
    "y_pred_rfr=rfr.predict(X_test) \n",
    "mean_absolute_error(y_test, y_pred_rfr, multioutput='raw_values') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fitRFR=rfr.fit(X_train, y_train)  \n",
    "#from pprint import pprint\n",
    "#pprint(vars(fitRFR))\n",
    "#dir(fitRFR)\n",
    "#getattr(fitRFR, 'feature_importances_')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE en entrenamiento\n",
      "1723.1881163970709\n",
      "MAE en test\n",
      "1610.587101927204\n"
     ]
    }
   ],
   "source": [
    "gbr = GradientBoostingRegressor(n_estimators=10, random_state=42, criterion='mae', max_features=100, loss='lad')\n",
    "gbr.fit(X_train, y_train.iloc[:,0])   \n",
    "y_pred_gbr=gbr.predict(X_test)\n",
    "y_pred_train = gbr.predict(X_train)\n",
    "print('MAE en entrenamiento')\n",
    "print(mean_absolute_error(y_train.iloc[:,0], y_pred_train))\n",
    "print('MAE en test')\n",
    "print(mean_absolute_error(y_test.iloc[:,0], y_pred_gbr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gbr.fit(X_train, y_train.iloc[:,0])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_pred_gbr=gbr.predict(X_test) \n",
    "#mean_absolute_error(y_test.iloc[:,0], y_pred_gbr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cuando se intenta estimar las cuatro variables en forma simultánea se obtiene un mensaje de error, lo que indica que probablemente el método solo funciona con una etiqueta. Por eso, por el momento solo se estima una de las variables SHP."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Red neuronal (MLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = MLPRegressor(hidden_layer_sizes=(10,),  activation='relu', solver='adam',    alpha=0.001,batch_size='auto',\n",
    "               learning_rate='constant', learning_rate_init=0.01, power_t=0.5, max_iter=1000, shuffle=True,\n",
    "               random_state=None, tol=0.0001, verbose=False, warm_start=False, momentum=0.9,\n",
    "               nesterovs_momentum=True, early_stopping=False, validation_fraction=0.1, beta_1=0.9, beta_2=0.999,\n",
    "               epsilon=1e-08)\n",
    "\n",
    "reg = reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1763.47306172,   11.6208516 ,    8.27505239,    6.62763106])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_mlp = reg.predict(X_test)\n",
    "mean_absolute_error(y_test, y_pred_mlp, multioutput='raw_values') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En estos modelos base sin optimizar hiperparámetros, tiene un desempeño superior la regresión random forest.\n",
    "En el caso de la regresión gradient boosting no se pudo implementar estimaciones para más de una etiqueta en forma simultánea."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Actividad 3\n",
    "\n",
    "Para estos nuevos modelos tunear hiper-parámetros. Para las evaluaciones utilizar la técnica de k-fold cross-validation (ver cross-validation ) y explicar los resultados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta actividad directamente se tunean los hiperparámetros y se comparan los modelos de acuerdo al MAE. \n",
    "No se realiza la actividad 4, porque el score F1 no aplica a problemas de regresión. Se suple eas actividad justamente por medio del uso del MAE en esta actividad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# definición de métrica para usar con GridSearchCV\n",
    "MAE = make_scorer(mean_absolute_error,greater_is_better=False)\n",
    "# no se puede usar el argumento multioutput con el setting \"raw_values\" porque se el scorer debe ser un único número"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_forest_forecast(X_train,X_test,y_train, y_test):\n",
    "    \n",
    "    rfr = RandomForestRegressor(n_jobs=1, random_state=0)\n",
    "    param_grid = {'n_estimators': [10,20, 50], 'max_depth':[10,20,50]}\n",
    "    # 'n_estimators': [1000], 'max_features': [10,15,20,25], 'max_depth':[20,20,25,25,]}\n",
    "    model = GridSearchCV(estimator=rfr, param_grid=param_grid, n_jobs=1, cv=10, scoring=MAE)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_train = model.predict(X_train)\n",
    "    \n",
    "    print('Random forest regression...')\n",
    "    print('Mejores Parámetros:')\n",
    "    print(model.best_params_)\n",
    "    print('Best CV Score:')\n",
    "    print(-model.best_score_)\n",
    "    print('MAE en entrenamiento:')\n",
    "    print(mean_absolute_error(y_train, y_pred_train, multioutput= 'raw_values'))\n",
    "    print('MAE en test:')\n",
    "    print(mean_absolute_error(y_test, y_pred, multioutput= 'raw_values'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:813: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random forest regression...\n",
      "Mejores Parámetros:\n",
      "{'max_depth': 50, 'n_estimators': 50}\n",
      "Best CV Score:\n",
      "408.91731615925863\n",
      "MAE en entrenamiento:\n",
      "[876.55765187   7.99337243   5.85359339   4.58556026]\n",
      "MAE en test:\n",
      "[1518.36575481   10.60968949    7.85397689    6.30025063]\n"
     ]
    }
   ],
   "source": [
    "random_forest_forecast(X_train,X_test,y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El modelo sobreajusta demasiado, porque el desempeño en test es muy inferior al desempeño en la muestra de entrenamiento. Es intrigante que empeora el modelo al seleccionar los hiperparámetos por cross validation ( en el modelo original sin tunear hiperparámetros se tenía un mejor desempeño en test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_boosting_forecast(X_train,X_test,y_train, y_test):\n",
    "    \n",
    "    gbr = GradientBoostingRegressor(loss='lad', random_state=5,criterion='mae')\n",
    "    param_grid = {'n_estimators': [10], 'learning_rate':[0.01,0.1,1,10]}\n",
    "    # 'n_estimators': [10], 'max_features': [10,15,20,25], 'learning_rate':[0.01,0.1,1,10]}\n",
    "    model = GridSearchCV(estimator=gbr, param_grid=param_grid,  cv=10)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_train = model.predict(X_train)\n",
    "    \n",
    "    print('Gradient boosting regression...')\n",
    "    print('Mejores Parámetros:')\n",
    "    print(model.best_params_)\n",
    "    print('Best CV Score:')\n",
    "    print(-model.best_score_)\n",
    "    print('MAE en entrenamiento:')\n",
    "    print(mean_absolute_error(y_train, y_pred_train, multioutput= 'raw_values'))\n",
    "    print('MAE en test:')\n",
    "    print(mean_absolute_error(y_test, y_pred, multioutput= 'raw_values'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:813: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient boosting regression...\n",
      "Mejores Parámetros:\n",
      "{'learning_rate': 1, 'n_estimators': 10}\n",
      "Best CV Score:\n",
      "-0.10258190582219315\n",
      "MAE en entrenamiento:\n",
      "[1515.22925149]\n",
      "MAE en test:\n",
      "[1453.32665832]\n"
     ]
    }
   ],
   "source": [
    "gradient_boosting_forecast(X_train,X_test,y_train.iloc[:,0], y_test.iloc[:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Red neuronal (MLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_layer_perceptron_forecast(X_train,X_test,y_train, y_test):\n",
    "    \n",
    "    mlp = MLPRegressor()\n",
    "    param_grid = {'solver': ['lbfgs'], 'max_iter': [1000 ], 'alpha': 10.0 ** -np.arange(1, 2), \n",
    "                  'hidden_layer_sizes':10*np.arange(10, 15), 'random_state':[5]}\n",
    "    model = GridSearchCV(estimator=mlp, param_grid=param_grid,  cv=10)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_train = model.predict(X_train)\n",
    "    \n",
    "    print('Multi-layer perceptron regression...')\n",
    "    print('Mejores Parámetros:')\n",
    "    print(model.best_params_)\n",
    "    print('Best CV Score:')\n",
    "    print(-model.best_score_)\n",
    "    print('MAE en entrenamiento:')\n",
    "    print(mean_absolute_error(y_train, y_pred_train, multioutput= 'raw_values'))\n",
    "    print('MAE en test:')\n",
    "    print(mean_absolute_error(y_test, y_pred, multioutput= 'raw_values'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:420: FutureWarning: The default value of multioutput (not exposed in score method) will change from 'variance_weighted' to 'uniform_average' in 0.23 to keep consistent with 'metrics.r2_score'. To specify the default value manually and avoid the warning, please either call 'metrics.r2_score' directly or make a custom scorer with 'metrics.make_scorer' (the built-in scorer 'r2' uses multioutput='uniform_average').\n",
      "  \"multioutput='uniform_average').\", FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:420: FutureWarning: The default value of multioutput (not exposed in score method) will change from 'variance_weighted' to 'uniform_average' in 0.23 to keep consistent with 'metrics.r2_score'. To specify the default value manually and avoid the warning, please either call 'metrics.r2_score' directly or make a custom scorer with 'metrics.make_scorer' (the built-in scorer 'r2' uses multioutput='uniform_average').\n",
      "  \"multioutput='uniform_average').\", FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:420: FutureWarning: The default value of multioutput (not exposed in score method) will change from 'variance_weighted' to 'uniform_average' in 0.23 to keep consistent with 'metrics.r2_score'. To specify the default value manually and avoid the warning, please either call 'metrics.r2_score' directly or make a custom scorer with 'metrics.make_scorer' (the built-in scorer 'r2' uses multioutput='uniform_average').\n",
      "  \"multioutput='uniform_average').\", FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:420: FutureWarning: The default value of multioutput (not exposed in score method) will change from 'variance_weighted' to 'uniform_average' in 0.23 to keep consistent with 'metrics.r2_score'. To specify the default value manually and avoid the warning, please either call 'metrics.r2_score' directly or make a custom scorer with 'metrics.make_scorer' (the built-in scorer 'r2' uses multioutput='uniform_average').\n",
      "  \"multioutput='uniform_average').\", FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:420: FutureWarning: The default value of multioutput (not exposed in score method) will change from 'variance_weighted' to 'uniform_average' in 0.23 to keep consistent with 'metrics.r2_score'. To specify the default value manually and avoid the warning, please either call 'metrics.r2_score' directly or make a custom scorer with 'metrics.make_scorer' (the built-in scorer 'r2' uses multioutput='uniform_average').\n",
      "  \"multioutput='uniform_average').\", FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:420: FutureWarning: The default value of multioutput (not exposed in score method) will change from 'variance_weighted' to 'uniform_average' in 0.23 to keep consistent with 'metrics.r2_score'. To specify the default value manually and avoid the warning, please either call 'metrics.r2_score' directly or make a custom scorer with 'metrics.make_scorer' (the built-in scorer 'r2' uses multioutput='uniform_average').\n",
      "  \"multioutput='uniform_average').\", FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:420: FutureWarning: The default value of multioutput (not exposed in score method) will change from 'variance_weighted' to 'uniform_average' in 0.23 to keep consistent with 'metrics.r2_score'. To specify the default value manually and avoid the warning, please either call 'metrics.r2_score' directly or make a custom scorer with 'metrics.make_scorer' (the built-in scorer 'r2' uses multioutput='uniform_average').\n",
      "  \"multioutput='uniform_average').\", FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:420: FutureWarning: The default value of multioutput (not exposed in score method) will change from 'variance_weighted' to 'uniform_average' in 0.23 to keep consistent with 'metrics.r2_score'. To specify the default value manually and avoid the warning, please either call 'metrics.r2_score' directly or make a custom scorer with 'metrics.make_scorer' (the built-in scorer 'r2' uses multioutput='uniform_average').\n",
      "  \"multioutput='uniform_average').\", FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:420: FutureWarning: The default value of multioutput (not exposed in score method) will change from 'variance_weighted' to 'uniform_average' in 0.23 to keep consistent with 'metrics.r2_score'. To specify the default value manually and avoid the warning, please either call 'metrics.r2_score' directly or make a custom scorer with 'metrics.make_scorer' (the built-in scorer 'r2' uses multioutput='uniform_average').\n",
      "  \"multioutput='uniform_average').\", FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:420: FutureWarning: The default value of multioutput (not exposed in score method) will change from 'variance_weighted' to 'uniform_average' in 0.23 to keep consistent with 'metrics.r2_score'. To specify the default value manually and avoid the warning, please either call 'metrics.r2_score' directly or make a custom scorer with 'metrics.make_scorer' (the built-in scorer 'r2' uses multioutput='uniform_average').\n",
      "  \"multioutput='uniform_average').\", FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:420: FutureWarning: The default value of multioutput (not exposed in score method) will change from 'variance_weighted' to 'uniform_average' in 0.23 to keep consistent with 'metrics.r2_score'. To specify the default value manually and avoid the warning, please either call 'metrics.r2_score' directly or make a custom scorer with 'metrics.make_scorer' (the built-in scorer 'r2' uses multioutput='uniform_average').\n",
      "  \"multioutput='uniform_average').\", FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:420: FutureWarning: The default value of multioutput (not exposed in score method) will change from 'variance_weighted' to 'uniform_average' in 0.23 to keep consistent with 'metrics.r2_score'. To specify the default value manually and avoid the warning, please either call 'metrics.r2_score' directly or make a custom scorer with 'metrics.make_scorer' (the built-in scorer 'r2' uses multioutput='uniform_average').\n",
      "  \"multioutput='uniform_average').\", FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:420: FutureWarning: The default value of multioutput (not exposed in score method) will change from 'variance_weighted' to 'uniform_average' in 0.23 to keep consistent with 'metrics.r2_score'. To specify the default value manually and avoid the warning, please either call 'metrics.r2_score' directly or make a custom scorer with 'metrics.make_scorer' (the built-in scorer 'r2' uses multioutput='uniform_average').\n",
      "  \"multioutput='uniform_average').\", FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:420: FutureWarning: The default value of multioutput (not exposed in score method) will change from 'variance_weighted' to 'uniform_average' in 0.23 to keep consistent with 'metrics.r2_score'. To specify the default value manually and avoid the warning, please either call 'metrics.r2_score' directly or make a custom scorer with 'metrics.make_scorer' (the built-in scorer 'r2' uses multioutput='uniform_average').\n",
      "  \"multioutput='uniform_average').\", FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:420: FutureWarning: The default value of multioutput (not exposed in score method) will change from 'variance_weighted' to 'uniform_average' in 0.23 to keep consistent with 'metrics.r2_score'. To specify the default value manually and avoid the warning, please either call 'metrics.r2_score' directly or make a custom scorer with 'metrics.make_scorer' (the built-in scorer 'r2' uses multioutput='uniform_average').\n",
      "  \"multioutput='uniform_average').\", FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:420: FutureWarning: The default value of multioutput (not exposed in score method) will change from 'variance_weighted' to 'uniform_average' in 0.23 to keep consistent with 'metrics.r2_score'. To specify the default value manually and avoid the warning, please either call 'metrics.r2_score' directly or make a custom scorer with 'metrics.make_scorer' (the built-in scorer 'r2' uses multioutput='uniform_average').\n",
      "  \"multioutput='uniform_average').\", FutureWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:420: FutureWarning: The default value of multioutput (not exposed in score method) will change from 'variance_weighted' to 'uniform_average' in 0.23 to keep consistent with 'metrics.r2_score'. To specify the default value manually and avoid the warning, please either call 'metrics.r2_score' directly or make a custom scorer with 'metrics.make_scorer' (the built-in scorer 'r2' uses multioutput='uniform_average').\n",
      "  \"multioutput='uniform_average').\", FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:420: FutureWarning: The default value of multioutput (not exposed in score method) will change from 'variance_weighted' to 'uniform_average' in 0.23 to keep consistent with 'metrics.r2_score'. To specify the default value manually and avoid the warning, please either call 'metrics.r2_score' directly or make a custom scorer with 'metrics.make_scorer' (the built-in scorer 'r2' uses multioutput='uniform_average').\n",
      "  \"multioutput='uniform_average').\", FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:420: FutureWarning: The default value of multioutput (not exposed in score method) will change from 'variance_weighted' to 'uniform_average' in 0.23 to keep consistent with 'metrics.r2_score'. To specify the default value manually and avoid the warning, please either call 'metrics.r2_score' directly or make a custom scorer with 'metrics.make_scorer' (the built-in scorer 'r2' uses multioutput='uniform_average').\n",
      "  \"multioutput='uniform_average').\", FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:420: FutureWarning: The default value of multioutput (not exposed in score method) will change from 'variance_weighted' to 'uniform_average' in 0.23 to keep consistent with 'metrics.r2_score'. To specify the default value manually and avoid the warning, please either call 'metrics.r2_score' directly or make a custom scorer with 'metrics.make_scorer' (the built-in scorer 'r2' uses multioutput='uniform_average').\n",
      "  \"multioutput='uniform_average').\", FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:420: FutureWarning: The default value of multioutput (not exposed in score method) will change from 'variance_weighted' to 'uniform_average' in 0.23 to keep consistent with 'metrics.r2_score'. To specify the default value manually and avoid the warning, please either call 'metrics.r2_score' directly or make a custom scorer with 'metrics.make_scorer' (the built-in scorer 'r2' uses multioutput='uniform_average').\n",
      "  \"multioutput='uniform_average').\", FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:420: FutureWarning: The default value of multioutput (not exposed in score method) will change from 'variance_weighted' to 'uniform_average' in 0.23 to keep consistent with 'metrics.r2_score'. To specify the default value manually and avoid the warning, please either call 'metrics.r2_score' directly or make a custom scorer with 'metrics.make_scorer' (the built-in scorer 'r2' uses multioutput='uniform_average').\n",
      "  \"multioutput='uniform_average').\", FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:420: FutureWarning: The default value of multioutput (not exposed in score method) will change from 'variance_weighted' to 'uniform_average' in 0.23 to keep consistent with 'metrics.r2_score'. To specify the default value manually and avoid the warning, please either call 'metrics.r2_score' directly or make a custom scorer with 'metrics.make_scorer' (the built-in scorer 'r2' uses multioutput='uniform_average').\n",
      "  \"multioutput='uniform_average').\", FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:420: FutureWarning: The default value of multioutput (not exposed in score method) will change from 'variance_weighted' to 'uniform_average' in 0.23 to keep consistent with 'metrics.r2_score'. To specify the default value manually and avoid the warning, please either call 'metrics.r2_score' directly or make a custom scorer with 'metrics.make_scorer' (the built-in scorer 'r2' uses multioutput='uniform_average').\n",
      "  \"multioutput='uniform_average').\", FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:420: FutureWarning: The default value of multioutput (not exposed in score method) will change from 'variance_weighted' to 'uniform_average' in 0.23 to keep consistent with 'metrics.r2_score'. To specify the default value manually and avoid the warning, please either call 'metrics.r2_score' directly or make a custom scorer with 'metrics.make_scorer' (the built-in scorer 'r2' uses multioutput='uniform_average').\n",
      "  \"multioutput='uniform_average').\", FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:420: FutureWarning: The default value of multioutput (not exposed in score method) will change from 'variance_weighted' to 'uniform_average' in 0.23 to keep consistent with 'metrics.r2_score'. To specify the default value manually and avoid the warning, please either call 'metrics.r2_score' directly or make a custom scorer with 'metrics.make_scorer' (the built-in scorer 'r2' uses multioutput='uniform_average').\n",
      "  \"multioutput='uniform_average').\", FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:420: FutureWarning: The default value of multioutput (not exposed in score method) will change from 'variance_weighted' to 'uniform_average' in 0.23 to keep consistent with 'metrics.r2_score'. To specify the default value manually and avoid the warning, please either call 'metrics.r2_score' directly or make a custom scorer with 'metrics.make_scorer' (the built-in scorer 'r2' uses multioutput='uniform_average').\n",
      "  \"multioutput='uniform_average').\", FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:420: FutureWarning: The default value of multioutput (not exposed in score method) will change from 'variance_weighted' to 'uniform_average' in 0.23 to keep consistent with 'metrics.r2_score'. To specify the default value manually and avoid the warning, please either call 'metrics.r2_score' directly or make a custom scorer with 'metrics.make_scorer' (the built-in scorer 'r2' uses multioutput='uniform_average').\n",
      "  \"multioutput='uniform_average').\", FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:420: FutureWarning: The default value of multioutput (not exposed in score method) will change from 'variance_weighted' to 'uniform_average' in 0.23 to keep consistent with 'metrics.r2_score'. To specify the default value manually and avoid the warning, please either call 'metrics.r2_score' directly or make a custom scorer with 'metrics.make_scorer' (the built-in scorer 'r2' uses multioutput='uniform_average').\n",
      "  \"multioutput='uniform_average').\", FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:420: FutureWarning: The default value of multioutput (not exposed in score method) will change from 'variance_weighted' to 'uniform_average' in 0.23 to keep consistent with 'metrics.r2_score'. To specify the default value manually and avoid the warning, please either call 'metrics.r2_score' directly or make a custom scorer with 'metrics.make_scorer' (the built-in scorer 'r2' uses multioutput='uniform_average').\n",
      "  \"multioutput='uniform_average').\", FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:420: FutureWarning: The default value of multioutput (not exposed in score method) will change from 'variance_weighted' to 'uniform_average' in 0.23 to keep consistent with 'metrics.r2_score'. To specify the default value manually and avoid the warning, please either call 'metrics.r2_score' directly or make a custom scorer with 'metrics.make_scorer' (the built-in scorer 'r2' uses multioutput='uniform_average').\n",
      "  \"multioutput='uniform_average').\", FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:420: FutureWarning: The default value of multioutput (not exposed in score method) will change from 'variance_weighted' to 'uniform_average' in 0.23 to keep consistent with 'metrics.r2_score'. To specify the default value manually and avoid the warning, please either call 'metrics.r2_score' directly or make a custom scorer with 'metrics.make_scorer' (the built-in scorer 'r2' uses multioutput='uniform_average').\n",
      "  \"multioutput='uniform_average').\", FutureWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:420: FutureWarning: The default value of multioutput (not exposed in score method) will change from 'variance_weighted' to 'uniform_average' in 0.23 to keep consistent with 'metrics.r2_score'. To specify the default value manually and avoid the warning, please either call 'metrics.r2_score' directly or make a custom scorer with 'metrics.make_scorer' (the built-in scorer 'r2' uses multioutput='uniform_average').\n",
      "  \"multioutput='uniform_average').\", FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:420: FutureWarning: The default value of multioutput (not exposed in score method) will change from 'variance_weighted' to 'uniform_average' in 0.23 to keep consistent with 'metrics.r2_score'. To specify the default value manually and avoid the warning, please either call 'metrics.r2_score' directly or make a custom scorer with 'metrics.make_scorer' (the built-in scorer 'r2' uses multioutput='uniform_average').\n",
      "  \"multioutput='uniform_average').\", FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:420: FutureWarning: The default value of multioutput (not exposed in score method) will change from 'variance_weighted' to 'uniform_average' in 0.23 to keep consistent with 'metrics.r2_score'. To specify the default value manually and avoid the warning, please either call 'metrics.r2_score' directly or make a custom scorer with 'metrics.make_scorer' (the built-in scorer 'r2' uses multioutput='uniform_average').\n",
      "  \"multioutput='uniform_average').\", FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:420: FutureWarning: The default value of multioutput (not exposed in score method) will change from 'variance_weighted' to 'uniform_average' in 0.23 to keep consistent with 'metrics.r2_score'. To specify the default value manually and avoid the warning, please either call 'metrics.r2_score' directly or make a custom scorer with 'metrics.make_scorer' (the built-in scorer 'r2' uses multioutput='uniform_average').\n",
      "  \"multioutput='uniform_average').\", FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:420: FutureWarning: The default value of multioutput (not exposed in score method) will change from 'variance_weighted' to 'uniform_average' in 0.23 to keep consistent with 'metrics.r2_score'. To specify the default value manually and avoid the warning, please either call 'metrics.r2_score' directly or make a custom scorer with 'metrics.make_scorer' (the built-in scorer 'r2' uses multioutput='uniform_average').\n",
      "  \"multioutput='uniform_average').\", FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:420: FutureWarning: The default value of multioutput (not exposed in score method) will change from 'variance_weighted' to 'uniform_average' in 0.23 to keep consistent with 'metrics.r2_score'. To specify the default value manually and avoid the warning, please either call 'metrics.r2_score' directly or make a custom scorer with 'metrics.make_scorer' (the built-in scorer 'r2' uses multioutput='uniform_average').\n",
      "  \"multioutput='uniform_average').\", FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:420: FutureWarning: The default value of multioutput (not exposed in score method) will change from 'variance_weighted' to 'uniform_average' in 0.23 to keep consistent with 'metrics.r2_score'. To specify the default value manually and avoid the warning, please either call 'metrics.r2_score' directly or make a custom scorer with 'metrics.make_scorer' (the built-in scorer 'r2' uses multioutput='uniform_average').\n",
      "  \"multioutput='uniform_average').\", FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:420: FutureWarning: The default value of multioutput (not exposed in score method) will change from 'variance_weighted' to 'uniform_average' in 0.23 to keep consistent with 'metrics.r2_score'. To specify the default value manually and avoid the warning, please either call 'metrics.r2_score' directly or make a custom scorer with 'metrics.make_scorer' (the built-in scorer 'r2' uses multioutput='uniform_average').\n",
      "  \"multioutput='uniform_average').\", FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:420: FutureWarning: The default value of multioutput (not exposed in score method) will change from 'variance_weighted' to 'uniform_average' in 0.23 to keep consistent with 'metrics.r2_score'. To specify the default value manually and avoid the warning, please either call 'metrics.r2_score' directly or make a custom scorer with 'metrics.make_scorer' (the built-in scorer 'r2' uses multioutput='uniform_average').\n",
      "  \"multioutput='uniform_average').\", FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:420: FutureWarning: The default value of multioutput (not exposed in score method) will change from 'variance_weighted' to 'uniform_average' in 0.23 to keep consistent with 'metrics.r2_score'. To specify the default value manually and avoid the warning, please either call 'metrics.r2_score' directly or make a custom scorer with 'metrics.make_scorer' (the built-in scorer 'r2' uses multioutput='uniform_average').\n",
      "  \"multioutput='uniform_average').\", FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:420: FutureWarning: The default value of multioutput (not exposed in score method) will change from 'variance_weighted' to 'uniform_average' in 0.23 to keep consistent with 'metrics.r2_score'. To specify the default value manually and avoid the warning, please either call 'metrics.r2_score' directly or make a custom scorer with 'metrics.make_scorer' (the built-in scorer 'r2' uses multioutput='uniform_average').\n",
      "  \"multioutput='uniform_average').\", FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:420: FutureWarning: The default value of multioutput (not exposed in score method) will change from 'variance_weighted' to 'uniform_average' in 0.23 to keep consistent with 'metrics.r2_score'. To specify the default value manually and avoid the warning, please either call 'metrics.r2_score' directly or make a custom scorer with 'metrics.make_scorer' (the built-in scorer 'r2' uses multioutput='uniform_average').\n",
      "  \"multioutput='uniform_average').\", FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:420: FutureWarning: The default value of multioutput (not exposed in score method) will change from 'variance_weighted' to 'uniform_average' in 0.23 to keep consistent with 'metrics.r2_score'. To specify the default value manually and avoid the warning, please either call 'metrics.r2_score' directly or make a custom scorer with 'metrics.make_scorer' (the built-in scorer 'r2' uses multioutput='uniform_average').\n",
      "  \"multioutput='uniform_average').\", FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:420: FutureWarning: The default value of multioutput (not exposed in score method) will change from 'variance_weighted' to 'uniform_average' in 0.23 to keep consistent with 'metrics.r2_score'. To specify the default value manually and avoid the warning, please either call 'metrics.r2_score' directly or make a custom scorer with 'metrics.make_scorer' (the built-in scorer 'r2' uses multioutput='uniform_average').\n",
      "  \"multioutput='uniform_average').\", FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:420: FutureWarning: The default value of multioutput (not exposed in score method) will change from 'variance_weighted' to 'uniform_average' in 0.23 to keep consistent with 'metrics.r2_score'. To specify the default value manually and avoid the warning, please either call 'metrics.r2_score' directly or make a custom scorer with 'metrics.make_scorer' (the built-in scorer 'r2' uses multioutput='uniform_average').\n",
      "  \"multioutput='uniform_average').\", FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:420: FutureWarning: The default value of multioutput (not exposed in score method) will change from 'variance_weighted' to 'uniform_average' in 0.23 to keep consistent with 'metrics.r2_score'. To specify the default value manually and avoid the warning, please either call 'metrics.r2_score' directly or make a custom scorer with 'metrics.make_scorer' (the built-in scorer 'r2' uses multioutput='uniform_average').\n",
      "  \"multioutput='uniform_average').\", FutureWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:420: FutureWarning: The default value of multioutput (not exposed in score method) will change from 'variance_weighted' to 'uniform_average' in 0.23 to keep consistent with 'metrics.r2_score'. To specify the default value manually and avoid the warning, please either call 'metrics.r2_score' directly or make a custom scorer with 'metrics.make_scorer' (the built-in scorer 'r2' uses multioutput='uniform_average').\n",
      "  \"multioutput='uniform_average').\", FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:420: FutureWarning: The default value of multioutput (not exposed in score method) will change from 'variance_weighted' to 'uniform_average' in 0.23 to keep consistent with 'metrics.r2_score'. To specify the default value manually and avoid the warning, please either call 'metrics.r2_score' directly or make a custom scorer with 'metrics.make_scorer' (the built-in scorer 'r2' uses multioutput='uniform_average').\n",
      "  \"multioutput='uniform_average').\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multi-layer perceptron regression...\n",
      "Mejores Parámetros:\n",
      "{'alpha': 0.1, 'hidden_layer_sizes': 110, 'max_iter': 1000, 'random_state': 5, 'solver': 'lbfgs'}\n",
      "Best CV Score:\n",
      "-0.15458933982650958\n",
      "MAE en entrenamiento:\n",
      "[1959.21856534   45.38964898   31.67319572   17.10271971]\n",
      "MAE en test:\n",
      "[1836.9966037    45.63799425   31.94461493   16.2676895 ]\n"
     ]
    }
   ],
   "source": [
    "multi_layer_perceptron_forecast(X_train,X_test,y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se tiene un desempeño marcadamente inferior al de las regresiones random forest y gradient boosting. Además es mejor el ajuste en test que en entenamiento. Por lo tanto probablemente se deba probar un arquitectura mas compleja."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Actividad 4\n",
    "\n",
    "Elegir el mejor modelo entrenado hasta el momento según f1-score. Comparar las métricas de este modelo vs. las métricas de evaluar 4 modelos por separado, un modelo para cada uno de los targets. Interpretar los resultados. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No se emplea el f1-score porque no aplica a problemas de regresión. En la actividad 3 se computaron las métricas MAE, para cada uno de los modelos seleccionados, dando mejores resultados la regresión random forest. En esta actividad se agregan las métricas que se obtienen al estimar modelos para cada variable por separado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regresiones con un solo output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regresiones random forest con un output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def univariate_random_forest_forecast(X_train,X_test,y_train, y_test):\n",
    "    \n",
    "    rfr = RandomForestRegressor(n_jobs=1, random_state=0)\n",
    "    param_grid = {'n_estimators': [10,20, 50], 'max_depth':[10,20,50]}\n",
    "    # 'n_estimators': [1000], 'max_features': [10,15,20,25], 'max_depth':[20,20,25,25,]}\n",
    "    model = GridSearchCV(estimator=rfr, param_grid=param_grid, n_jobs=1, cv=10, scoring=MAE)\n",
    "    model.fit(X_train, y_train.iloc[:,0])\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_train = model.predict(X_train)\n",
    "    \n",
    "    print('Random forest regression para SHP_WEIGHT')\n",
    "    print('Mejores Parámetros:')\n",
    "    print(model.best_params_)\n",
    "    print('Best CV Score:')\n",
    "    print(-model.best_score_)\n",
    "    print('MAE en entrenamiento:')\n",
    "    print(mean_absolute_error(y_train.iloc[:,0], y_pred_train))\n",
    "    print('MAE en test:')\n",
    "    print(mean_absolute_error(y_test.iloc[:,0], y_pred))\n",
    "    \n",
    "    rfr = RandomForestRegressor(n_jobs=1, random_state=0)\n",
    "    param_grid = {'n_estimators': [10,20, 50], 'max_depth':[10,20,50]}\n",
    "    # 'n_estimators': [1000], 'max_features': [10,15,20,25], 'max_depth':[20,20,25,25,]}\n",
    "    model = GridSearchCV(estimator=rfr, param_grid=param_grid, n_jobs=1, cv=10, scoring=MAE)\n",
    "    model.fit(X_train, y_train.iloc[:,1])\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_train = model.predict(X_train)\n",
    "    \n",
    "    print('Random forest regression para SHP_LENGTH')\n",
    "    print('Mejores Parámetros:')\n",
    "    print(model.best_params_)\n",
    "    print('Best CV Score:')\n",
    "    print(-model.best_score_)\n",
    "    print('MAE en entrenamiento:')\n",
    "    print(mean_absolute_error(y_train.iloc[:,1], y_pred_train))\n",
    "    print('MAE en test:')\n",
    "    print(mean_absolute_error(y_test.iloc[:,1], y_pred))\n",
    "    \n",
    "    rfr = RandomForestRegressor(n_jobs=1, random_state=0)\n",
    "    param_grid = {'n_estimators': [10,20, 50], 'max_depth':[10,20,50]}\n",
    "    # 'n_estimators': [1000], 'max_features': [10,15,20,25], 'max_depth':[20,20,25,25,]}\n",
    "    model = GridSearchCV(estimator=rfr, param_grid=param_grid, n_jobs=1, cv=10, scoring=MAE)\n",
    "    model.fit(X_train, y_train.iloc[:,2])\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_train = model.predict(X_train)\n",
    "    \n",
    "    print('Random forest regression para SHP_WIDTH')\n",
    "    print('Mejores Parámetros:')\n",
    "    print(model.best_params_)\n",
    "    print('Best CV Score:')\n",
    "    print(-model.best_score_)\n",
    "    print('MAE en entrenamiento:')\n",
    "    print(mean_absolute_error(y_train.iloc[:,2], y_pred_train))\n",
    "    print('MAE en test:')\n",
    "    print(mean_absolute_error(y_test.iloc[:,2], y_pred))\n",
    "    \n",
    "    rfr = RandomForestRegressor(n_jobs=1, random_state=0)\n",
    "    param_grid = {'n_estimators': [10,20, 50], 'max_depth':[10,20,50]}\n",
    "    # 'n_estimators': [1000], 'max_features': [10,15,20,25], 'max_depth':[20,20,25,25,]}\n",
    "    model = GridSearchCV(estimator=rfr, param_grid=param_grid, n_jobs=1, cv=10, scoring=MAE)\n",
    "    model.fit(X_train, y_train.iloc[:,3])\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_train = model.predict(X_train)\n",
    "    \n",
    "    print('Random forest regression para SHP_HEIGHT')\n",
    "    print('Mejores Parámetros:')\n",
    "    print(model.best_params_)\n",
    "    print('Best CV Score:')\n",
    "    print(-model.best_score_)\n",
    "    print('MAE en entrenamiento:')\n",
    "    print(mean_absolute_error(y_train.iloc[:,3], y_pred_train))\n",
    "    print('MAE en test:')\n",
    "    print(mean_absolute_error(y_test.iloc[:,3], y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:813: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random forest regression para SHP_WEIGHT\n",
      "Mejores Parámetros:\n",
      "{'max_depth': 50, 'n_estimators': 50}\n",
      "Best CV Score:\n",
      "1610.155447361426\n",
      "MAE en entrenamiento:\n",
      "876.0011442243941\n",
      "MAE en test:\n",
      "1513.4209800097108\n",
      "Random forest regression para SHP_LENGTH\n",
      "Mejores Parámetros:\n",
      "{'max_depth': 50, 'n_estimators': 50}\n",
      "Best CV Score:\n",
      "11.050254622451193\n",
      "MAE en entrenamiento:\n",
      "7.006184542185479\n",
      "MAE en test:\n",
      "10.659708741151473\n",
      "Random forest regression para SHP_WIDTH\n",
      "Mejores Parámetros:\n",
      "{'max_depth': 50, 'n_estimators': 20}\n",
      "Best CV Score:\n",
      "7.842746099022772\n",
      "MAE en entrenamiento:\n",
      "5.012509491781855\n",
      "MAE en test:\n",
      "7.768557035037964\n",
      "Random forest regression para SHP_HEIGHT\n",
      "Mejores Parámetros:\n",
      "{'max_depth': 50, 'n_estimators': 50}\n",
      "Best CV Score:\n",
      "6.069047992965159\n",
      "MAE en entrenamiento:\n",
      "4.008781697138562\n",
      "MAE en test:\n",
      "6.063754965977446\n"
     ]
    }
   ],
   "source": [
    "univariate_random_forest_forecast(X_train,X_test,y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El ajuste de los modelos univariados es mejor que el del modelo multivariante para SHP_WEIGHT y SHP_LENGTH, ocurriendo lo contrario para SHP_WIDTH y SHP_HEIGHT."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regresiones gradient boosting con un output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def univariate_gradient_boosting_forecast(X_train,X_test,y_train, y_test):\n",
    "    \n",
    "    gbr = GradientBoostingRegressor(loss='lad', random_state=5,criterion='mae')\n",
    "    param_grid = {'n_estimators': [10], 'learning_rate':[0.01,0.1,1,10]}\n",
    "    # 'n_estimators': [10], 'max_features': [10,15,20,25], 'learning_rate':[0.01,0.1,1,10]}\n",
    "    model = GridSearchCV(estimator=gbr, param_grid=param_grid,  cv=10)\n",
    "    model.fit(X_train, y_train.iloc[:,0])\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_train = model.predict(X_train)\n",
    "    \n",
    "    print('Gradient boosting regression para SHP_WEIGHT')\n",
    "    print('Mejores Parámetros:')\n",
    "    print(model.best_params_)\n",
    "    print('Best CV Score:')\n",
    "    print(-model.best_score_)\n",
    "    print('MAE en entrenamiento:')\n",
    "    print(mean_absolute_error(y_train.iloc[:,0], y_pred_train))\n",
    "    print('MAE en test:')\n",
    "    print(mean_absolute_error(y_test.iloc[:,0], y_pred))\n",
    "    \n",
    "    gbr = GradientBoostingRegressor(loss='lad', random_state=5,criterion='mae')\n",
    "    param_grid = {'n_estimators': [10], 'learning_rate':[0.01,0.1,1,10]}\n",
    "    # 'n_estimators': [10], 'max_features': [10,15,20,25], 'learning_rate':[0.01,0.1,1,10]}\n",
    "    model = GridSearchCV(estimator=gbr, param_grid=param_grid,  cv=10)\n",
    "    model.fit(X_train, y_train.iloc[:,1])\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_train = model.predict(X_train)\n",
    "    \n",
    "    print('Gradient boosting regression para SHP_LENGTH')\n",
    "    print('Mejores Parámetros:')\n",
    "    print(model.best_params_)\n",
    "    print('Best CV Score:')\n",
    "    print(-model.best_score_)\n",
    "    print('MAE en entrenamiento:')\n",
    "    print(mean_absolute_error(y_train.iloc[:,1], y_pred_train))\n",
    "    print('MAE en test:')\n",
    "    print(mean_absolute_error(y_test.iloc[:,1], y_pred))\n",
    "    \n",
    "    gbr = GradientBoostingRegressor(loss='lad', random_state=5,criterion='mae')\n",
    "    param_grid = {'n_estimators': [10], 'learning_rate':[0.01,0.1,1,10]}\n",
    "    # 'n_estimators': [10], 'max_features': [10,15,20,25], 'learning_rate':[0.01,0.1,1,10]}\n",
    "    model = GridSearchCV(estimator=gbr, param_grid=param_grid,  cv=10)\n",
    "    model.fit(X_train, y_train.iloc[:,2])\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_train = model.predict(X_train)\n",
    "    \n",
    "    print('Gradient boosting regression para SHP_WIDTH')\n",
    "    print('Mejores Parámetros:')\n",
    "    print(model.best_params_)\n",
    "    print('Best CV Score:')\n",
    "    print(-model.best_score_)\n",
    "    print('MAE en entrenamiento:')\n",
    "    print(mean_absolute_error(y_train.iloc[:,2], y_pred_train))\n",
    "    print('MAE en test:')\n",
    "    print(mean_absolute_error(y_test.iloc[:,2], y_pred))\n",
    "    \n",
    "    gbr = GradientBoostingRegressor(loss='lad', random_state=5,criterion='mae')\n",
    "    param_grid = {'n_estimators': [10], 'learning_rate':[0.01,0.1,1,10]}\n",
    "    # 'n_estimators': [10], 'max_features': [10,15,20,25], 'learning_rate':[0.01,0.1,1,10]}\n",
    "    model = GridSearchCV(estimator=gbr, param_grid=param_grid,  cv=10)\n",
    "    model.fit(X_train, y_train.iloc[:,3])\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_train = model.predict(X_train)\n",
    "    \n",
    "    print('Gradient boosting regression para SHP_HEIGHT')\n",
    "    print('Mejores Parámetros:')\n",
    "    print(model.best_params_)\n",
    "    print('Best CV Score:')\n",
    "    print(-model.best_score_)\n",
    "    print('MAE en entrenamiento:')\n",
    "    print(mean_absolute_error(y_train.iloc[:,3], y_pred_train))\n",
    "    print('MAE en test:')\n",
    "    print(mean_absolute_error(y_test.iloc[:,3], y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:813: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient boosting regression para SHP_WEIGHT\n",
      "Mejores Parámetros:\n",
      "{'learning_rate': 1, 'n_estimators': 10}\n",
      "Best CV Score:\n",
      "-0.10258190582219315\n",
      "MAE en entrenamiento:\n",
      "1515.2292514876292\n",
      "MAE en test:\n",
      "1453.3266583229035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:813: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient boosting regression para SHP_LENGTH\n",
      "Mejores Parámetros:\n",
      "{'learning_rate': 1, 'n_estimators': 10}\n",
      "Best CV Score:\n",
      "-0.06265806150027763\n",
      "MAE en entrenamiento:\n",
      "10.465988098966488\n",
      "MAE en test:\n",
      "10.332290362953692\n",
      "Gradient boosting regression para SHP_WIDTH\n",
      "Mejores Parámetros:\n",
      "{'learning_rate': 1, 'n_estimators': 10}\n",
      "Best CV Score:\n",
      "-0.06006657216231128\n",
      "MAE en entrenamiento:\n",
      "7.670435327278421\n",
      "MAE en test:\n",
      "7.663078848560701\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:813: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient boosting regression para SHP_HEIGHT\n",
      "Mejores Parámetros:\n",
      "{'learning_rate': 1, 'n_estimators': 10}\n",
      "Best CV Score:\n",
      "-0.0674301968190712\n",
      "MAE en entrenamiento:\n",
      "5.802912621359224\n",
      "MAE en test:\n",
      "6.170337922403005\n"
     ]
    }
   ],
   "source": [
    "univariate_gradient_boosting_forecast(X_train,X_test,y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por lo general es mejor el desempeño de Gradient Boosting que Random Forest. En casi todos los casos tiene mejor ajuste en test y sobrejusta notablemente menos en el conjunto de entrenamiento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regresiones MLP con un output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def univariate_multi_layer_perceptron_forecast(X_train,X_test,y_train, y_test):\n",
    "    \n",
    "    mlp = MLPRegressor()\n",
    "    param_grid = {'solver': ['lbfgs'], 'max_iter': [1000 ], 'alpha': 10.0 ** -np.arange(1, 2), \n",
    "                  'hidden_layer_sizes':10*np.arange(10, 15), 'random_state':[5]}\n",
    "    model = GridSearchCV(estimator=mlp, param_grid=param_grid,  cv=10)\n",
    "    model.fit(X_train, y_train.iloc[:,0])\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_train = model.predict(X_train)\n",
    "    print('Multi-layer perceptron regression para SHP_WEIGHT')\n",
    "    print('Mejores Parámetros:')\n",
    "    print(model.best_params_)\n",
    "    print('Best CV Score:')\n",
    "    print(-model.best_score_)\n",
    "    print('MAE en entrenamiento:')\n",
    "    print(mean_absolute_error(y_train.iloc[:,0], y_pred_train))\n",
    "    print('MAE en test:')\n",
    "    print(mean_absolute_error(y_test.iloc[:,0], y_pred))\n",
    "    \n",
    "    mlp = MLPRegressor()\n",
    "    param_grid = {'solver': ['lbfgs'], 'max_iter': [1000 ], 'alpha': 10.0 ** -np.arange(1, 2), \n",
    "                  'hidden_layer_sizes':10*np.arange(10, 15), 'random_state':[5]}\n",
    "    model = GridSearchCV(estimator=mlp, param_grid=param_grid,  cv=10)\n",
    "    model.fit(X_train, y_train.iloc[:,1])\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_train = model.predict(X_train)\n",
    "    print('Multi-layer perceptron regression para SHP_LENGTH')\n",
    "    print('Mejores Parámetros:')\n",
    "    print(model.best_params_)\n",
    "    print('Best CV Score:')\n",
    "    print(-model.best_score_)\n",
    "    print('MAE en entrenamiento:')\n",
    "    print(mean_absolute_error(y_train.iloc[:,1], y_pred_train))\n",
    "    print('MAE en test:')\n",
    "    print(mean_absolute_error(y_test.iloc[:,1], y_pred))\n",
    "    \n",
    "    mlp = MLPRegressor()\n",
    "    param_grid = {'solver': ['lbfgs'], 'max_iter': [1000 ], 'alpha': 10.0 ** -np.arange(1, 2), \n",
    "                  'hidden_layer_sizes':10*np.arange(10, 15), 'random_state':[5]}\n",
    "    model = GridSearchCV(estimator=mlp, param_grid=param_grid,  cv=10)\n",
    "    model.fit(X_train, y_train.iloc[:,2])\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_train = model.predict(X_train)\n",
    "    print('Multi-layer perceptron regression para SHP_WIDTH')\n",
    "    print('Mejores Parámetros:')\n",
    "    print(model.best_params_)\n",
    "    print('Best CV Score:')\n",
    "    print(-model.best_score_)\n",
    "    print('MAE en entrenamiento:')\n",
    "    print(mean_absolute_error(y_train.iloc[:,2], y_pred_train))\n",
    "    print('MAE en test:')\n",
    "    print(mean_absolute_error(y_test.iloc[:,2], y_pred))\n",
    "    \n",
    "    mlp = MLPRegressor()\n",
    "    param_grid = {'solver': ['lbfgs'], 'max_iter': [1000 ], 'alpha': 10.0 ** -np.arange(1, 2), \n",
    "                  'hidden_layer_sizes':10*np.arange(10, 15), 'random_state':[5]}\n",
    "    model = GridSearchCV(estimator=mlp, param_grid=param_grid,  cv=10)\n",
    "    model.fit(X_train, y_train.iloc[:,3])\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_train = model.predict(X_train)\n",
    "    print('Multi-layer perceptron regression para SHP_HEIGHT')\n",
    "    print('Mejores Parámetros:')\n",
    "    print(model.best_params_)\n",
    "    print('Best CV Score:')\n",
    "    print(-model.best_score_)\n",
    "    print('MAE en entrenamiento:')\n",
    "    print(mean_absolute_error(y_train.iloc[:,3], y_pred_train))\n",
    "    print('MAE en test:')\n",
    "    print(mean_absolute_error(y_test.iloc[:,3], y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multi-layer perceptron regression para SHP_WEIGHT\n",
      "Mejores Parámetros:\n",
      "{'alpha': 0.1, 'hidden_layer_sizes': 120, 'max_iter': 1000, 'random_state': 5, 'solver': 'lbfgs'}\n",
      "Best CV Score:\n",
      "-0.18575144540361502\n",
      "MAE en entrenamiento:\n",
      "1901.349860132466\n",
      "MAE en test:\n",
      "1778.9600627448278\n",
      "Multi-layer perceptron regression para SHP_LENGTH\n",
      "Mejores Parámetros:\n",
      "{'alpha': 0.1, 'hidden_layer_sizes': 100, 'max_iter': 1000, 'random_state': 5, 'solver': 'lbfgs'}\n",
      "Best CV Score:\n",
      "-0.10325982423323989\n",
      "MAE en entrenamiento:\n",
      "11.903950526753693\n",
      "MAE en test:\n",
      "11.5657392216161\n"
     ]
    }
   ],
   "source": [
    "univariate_multi_layer_perceptron_forecast(X_train,X_test,y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Las regresiones MLP univariates funcionan un poco mejor que la multivariante."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra: búsqueda de una mejor arquitectura"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En las actividades previas se empleó MLP con una sola capa. En este apartado se escribe código para luego (con más poder de cómputo) construir una arquitectura más compleja. Para compensar el problema de carga computacional extra se reducen la cantidad de iteraciones máximas y el parámétro de cross validation.También se usa un único learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deep_MLP(X_train,X_test,y_train, y_test):\n",
    "    \n",
    "    mlp = MLPRegressor(random_state=5, max_iter=100, alpha=0.1, solver='adam')\n",
    "    param_grid = {'hidden_layer_sizes':[(100,50,25), (120,60,30),(50,25,10)]}\n",
    "    model = GridSearchCV(estimator=mlp, param_grid=param_grid,  cv=3)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_train = model.predict(X_train)\n",
    "    \n",
    "    print('Multi-layer perceptron regression...')\n",
    "    print('Mejores Parámetros:')\n",
    "    print(model.best_params_)\n",
    "    print('Best CV Score:')\n",
    "    print(-model.best_score_)\n",
    "    print('MAE en entrenamiento:')\n",
    "    print(mean_absolute_error(y_train, y_pred_train, multioutput= 'raw_values'))\n",
    "    print('MAE en test:')\n",
    "    print(mean_absolute_error(y_test, y_pred, multioutput= 'raw_values'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deep_MLP(X_train,X_test,y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
